{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“deeprm_functional.ipynb”copy",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunQiushi2020/Reinforcement-learning-with-tensorflow/blob/master/%E2%80%9Cdeeprm_functional_ipynb%E2%80%9Dcopy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiRouWhY5Kzm",
        "outputId": "2df61f16-6715-476d-c30c-802ce6b0d483",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 144628 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.23-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.23-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.23-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob1pSSVQ5jAP"
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua2AD8SuAY2E",
        "outputId": "33f6efff-d736-452a-be28-e2bfcbd12b70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGvtmZmzAgrX",
        "outputId": "7e56db6e-e72f-4cdf-d677-8d64cca83569",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd drive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCVt1SFGAg_Q",
        "outputId": "af5fe900-218b-4591-f356-fcbf62008da1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd colab"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J16U7FrRPCY"
      },
      "source": [
        "Hello!\n",
        "\n",
        "1.   Upload contents of archive to files\n",
        "2.   Use commands below to update lasagne and theano libraries\n",
        "3.   Create folder named 'data' (in the same folder with files)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWVi31oQQnEF",
        "outputId": "5e414df9-dda9-4db0-f808-93187f15633f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install --upgrade https://github.com/Theano/Theano/archive/master.zip\n",
        "!pip install --upgrade https://github.com/Lasagne/Lasagne/archive/master.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/Theano/Theano/archive/master.zip\n",
            "\u001b[?25l  Downloading https://github.com/Theano/Theano/archive/master.zip\n",
            "\u001b[K     - 27.0MB 722kB/s\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Theano==1.0.5+unknown) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Theano==1.0.5+unknown) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Theano==1.0.5+unknown) (1.15.0)\n",
            "Building wheels for collected packages: Theano\n",
            "  Building wheel for Theano (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Theano: filename=Theano-1.0.5+unknown-cp36-none-any.whl size=2667284 sha256=110f83dcf564a1bddd891d3ab73f711f4c25ac2df46f5248489fd0a3af835ca1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e16r0glc/wheels/33/73/96/0ed263c62a86e2485ea634e0d3ae8169d50fd66e3b252541db\n",
            "Successfully built Theano\n",
            "Installing collected packages: Theano\n",
            "  Found existing installation: Theano 1.0.5\n",
            "    Uninstalling Theano-1.0.5:\n",
            "      Successfully uninstalled Theano-1.0.5\n",
            "Successfully installed Theano-1.0.5+unknown\n",
            "Collecting https://github.com/Lasagne/Lasagne/archive/master.zip\n",
            "\u001b[?25l  Downloading https://github.com/Lasagne/Lasagne/archive/master.zip\n",
            "\u001b[K     | 1.0MB 4.0MB/s\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from Lasagne==0.2.dev1) (1.18.5)\n",
            "Building wheels for collected packages: Lasagne\n",
            "  Building wheel for Lasagne (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Lasagne: filename=Lasagne-0.2.dev1-cp36-none-any.whl size=122797 sha256=5ff804452f59a5632fe582dfc6369d6b902fa0acb83ea279d1bd34571e33e05e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q5q29kno/wheels/ca/4a/00/87f1777b229481fe76562df7c0cfb993bc88ed0cc37e3f0ed4\n",
            "Successfully built Lasagne\n",
            "Installing collected packages: Lasagne\n",
            "Successfully installed Lasagne-0.2.dev1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYAN2y2QTXI3"
      },
      "source": [
        "Basics: \n",
        "\n",
        "\n",
        "*   **pg_su.py** - supervised part of the model, produces weights of state-action pairs\n",
        "*   **pg_re** - reinforcement learning part of the model, takes weights of **pg_su.py** as an input\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-Rp1HV6RrGP"
      },
      "source": [
        "Next you want to obtain weights of supervised state-action pairs via this command\n",
        "\n",
        "\n",
        "```\n",
        "python launcher.py --exp_type=pg_su --simu_len=50 --num_ex=1000 --ofile=data/pg_su --out_freq=10 \n",
        "```\n",
        "\n",
        "\n",
        "Where:\n",
        "\n",
        "\n",
        "> --exp_type - parameter used to choose wether supervised of reinforcement version of the model to run </br>\n",
        "> --simu_len - lenght of one simulation </br>\n",
        "> --num_ex - number of epochs </br>\n",
        "> --ofile - path and naming format of outputed files </br>\n",
        "> --out_freq - how often to produce new files with weights (every n epochs)\n",
        "\n",
        "\n",
        "**USED num_ex = 10 AS AN EXAMPLE, ORIGINAL YOU CAN SEE ABOVE**\n",
        "\n",
        "**ERROR IS CAUSED BY KEYBOARD INTERRUPT BECAUSE I DIDNT WANT TO WAIT**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i8qL268OnWS"
      },
      "source": [
        "import time\n",
        "time_start=time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38FagmGrRqJv",
        "outputId": "2141cc6a-5ca3-4f41-c1af-8f88db1ff7d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python launcher.py --exp_type=pg_su --simu_len=50 --num_ex=10 --ofile=data/pg_su --out_freq=10 \n",
        "time_end=time.time()\n",
        "print('time cost',time_end-time_start,'s')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8336 of 10000 took 0.645s\n",
            "  training accuracy:\t\t77.83 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 8337 of 10000 took 0.651s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8338 of 10000 took 0.650s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 8339 of 10000 took 0.643s\n",
            "  training accuracy:\t\t80.59 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8340 of 10000 took 0.643s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8341 of 10000 took 0.662s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8342 of 10000 took 0.630s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8343 of 10000 took 0.656s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8344 of 10000 took 0.667s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8345 of 10000 took 0.667s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 8346 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8347 of 10000 took 0.671s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8348 of 10000 took 0.647s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8349 of 10000 took 0.655s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 8350 of 10000 took 0.667s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8351 of 10000 took 0.645s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8352 of 10000 took 0.628s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 8353 of 10000 took 0.672s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 8354 of 10000 took 0.663s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8355 of 10000 took 0.650s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8356 of 10000 took 0.672s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8357 of 10000 took 0.645s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8358 of 10000 took 0.681s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8359 of 10000 took 0.663s\n",
            "  training accuracy:\t\t78.00 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8360 of 10000 took 0.625s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8361 of 10000 took 0.649s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8362 of 10000 took 0.630s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8363 of 10000 took 0.640s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8364 of 10000 took 0.638s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8365 of 10000 took 0.664s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 8366 of 10000 took 0.655s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 8367 of 10000 took 0.648s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8368 of 10000 took 0.662s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t26.64 %\n",
            "Epoch 8369 of 10000 took 0.648s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 8370 of 10000 took 0.657s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 8371 of 10000 took 0.651s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8372 of 10000 took 0.648s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t32.53 %\n",
            "Epoch 8373 of 10000 took 0.655s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8374 of 10000 took 0.654s\n",
            "  training accuracy:\t\t80.67 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 8375 of 10000 took 0.658s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t38.75 %\n",
            "Epoch 8376 of 10000 took 0.668s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8377 of 10000 took 0.660s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8378 of 10000 took 0.655s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 8379 of 10000 took 0.654s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 8380 of 10000 took 0.656s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 8381 of 10000 took 0.655s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8382 of 10000 took 0.654s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8383 of 10000 took 0.656s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8384 of 10000 took 0.653s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t27.68 %\n",
            "Epoch 8385 of 10000 took 0.631s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8386 of 10000 took 0.658s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8387 of 10000 took 0.639s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8388 of 10000 took 0.640s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 8389 of 10000 took 0.660s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8390 of 10000 took 0.650s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8391 of 10000 took 0.641s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8392 of 10000 took 0.640s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8393 of 10000 took 0.636s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8394 of 10000 took 0.674s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8395 of 10000 took 0.665s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t31.14 %\n",
            "Epoch 8396 of 10000 took 0.644s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8397 of 10000 took 0.643s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8398 of 10000 took 0.661s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8399 of 10000 took 0.642s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t31.83 %\n",
            "Epoch 8400 of 10000 took 0.645s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 8401 of 10000 took 0.670s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8402 of 10000 took 0.667s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 8403 of 10000 took 0.659s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t29.41 %\n",
            "Epoch 8404 of 10000 took 0.648s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8405 of 10000 took 0.647s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t49.48 %\n",
            "Epoch 8406 of 10000 took 0.654s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t28.37 %\n",
            "Epoch 8407 of 10000 took 0.681s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 8408 of 10000 took 0.652s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8409 of 10000 took 0.636s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8410 of 10000 took 0.656s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 8411 of 10000 took 0.643s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8412 of 10000 took 0.650s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8413 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 8414 of 10000 took 0.663s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8415 of 10000 took 0.649s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 8416 of 10000 took 0.677s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t29.76 %\n",
            "Epoch 8417 of 10000 took 0.661s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8418 of 10000 took 0.654s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8419 of 10000 took 0.671s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8420 of 10000 took 0.671s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 8421 of 10000 took 0.662s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8422 of 10000 took 0.633s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t33.91 %\n",
            "Epoch 8423 of 10000 took 0.661s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8424 of 10000 took 0.659s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t37.37 %\n",
            "Epoch 8425 of 10000 took 0.671s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 8426 of 10000 took 0.665s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8427 of 10000 took 0.678s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8428 of 10000 took 0.662s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t33.22 %\n",
            "Epoch 8429 of 10000 took 0.653s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8430 of 10000 took 0.658s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 8431 of 10000 took 0.658s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t28.72 %\n",
            "Epoch 8432 of 10000 took 0.639s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t31.83 %\n",
            "Epoch 8433 of 10000 took 0.641s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 8434 of 10000 took 0.656s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8435 of 10000 took 0.651s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t29.41 %\n",
            "Epoch 8436 of 10000 took 0.651s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8437 of 10000 took 0.664s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8438 of 10000 took 0.652s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8439 of 10000 took 0.642s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8440 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t28.72 %\n",
            "Epoch 8441 of 10000 took 0.637s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8442 of 10000 took 0.636s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 8443 of 10000 took 0.654s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 8444 of 10000 took 0.660s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 8445 of 10000 took 0.677s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8446 of 10000 took 0.658s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8447 of 10000 took 0.661s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8448 of 10000 took 0.655s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8449 of 10000 took 0.653s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t31.83 %\n",
            "Epoch 8450 of 10000 took 0.659s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8451 of 10000 took 0.657s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 8452 of 10000 took 0.657s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8453 of 10000 took 0.668s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8454 of 10000 took 0.644s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 8455 of 10000 took 0.669s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t29.41 %\n",
            "Epoch 8456 of 10000 took 0.666s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8457 of 10000 took 0.648s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8458 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8459 of 10000 took 0.665s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8460 of 10000 took 0.636s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t37.37 %\n",
            "Epoch 8461 of 10000 took 0.663s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 8462 of 10000 took 0.645s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 8463 of 10000 took 0.635s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8464 of 10000 took 0.676s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 8465 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 8466 of 10000 took 0.650s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8467 of 10000 took 0.676s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8468 of 10000 took 0.672s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8469 of 10000 took 0.650s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 8470 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8471 of 10000 took 0.659s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8472 of 10000 took 0.640s\n",
            "  training accuracy:\t\t80.33 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 8473 of 10000 took 0.672s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t34.95 %\n",
            "Epoch 8474 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8475 of 10000 took 0.664s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8476 of 10000 took 0.662s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 8477 of 10000 took 0.634s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8478 of 10000 took 0.642s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8479 of 10000 took 0.661s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8480 of 10000 took 0.642s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8481 of 10000 took 0.656s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t37.72 %\n",
            "Epoch 8482 of 10000 took 0.631s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 8483 of 10000 took 0.643s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8484 of 10000 took 0.643s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 8485 of 10000 took 0.653s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8486 of 10000 took 0.657s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 8487 of 10000 took 0.639s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 8488 of 10000 took 0.660s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 8489 of 10000 took 0.666s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8490 of 10000 took 0.648s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 8491 of 10000 took 0.659s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8492 of 10000 took 0.624s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8493 of 10000 took 0.664s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t37.37 %\n",
            "Epoch 8494 of 10000 took 0.687s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 8495 of 10000 took 0.654s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8496 of 10000 took 0.647s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t31.49 %\n",
            "Epoch 8497 of 10000 took 0.671s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8498 of 10000 took 0.640s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 8499 of 10000 took 0.669s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8500 of 10000 took 0.653s\n",
            "  training accuracy:\t\t80.76 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 8501 of 10000 took 0.643s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8502 of 10000 took 0.632s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8503 of 10000 took 0.653s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t28.37 %\n",
            "Epoch 8504 of 10000 took 0.652s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8505 of 10000 took 0.665s\n",
            "  training accuracy:\t\t80.33 %\n",
            "  test accuracy:    \t\t38.06 %\n",
            "Epoch 8506 of 10000 took 0.652s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8507 of 10000 took 0.668s\n",
            "  training accuracy:\t\t78.00 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8508 of 10000 took 0.644s\n",
            "  training accuracy:\t\t80.50 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8509 of 10000 took 0.649s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8510 of 10000 took 0.650s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 8511 of 10000 took 0.653s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 8512 of 10000 took 0.633s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8513 of 10000 took 0.624s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8514 of 10000 took 0.648s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8515 of 10000 took 0.655s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8516 of 10000 took 0.640s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t37.37 %\n",
            "Epoch 8517 of 10000 took 0.667s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8518 of 10000 took 0.659s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8519 of 10000 took 0.632s\n",
            "  training accuracy:\t\t77.91 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8520 of 10000 took 0.652s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8521 of 10000 took 0.684s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8522 of 10000 took 0.635s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8523 of 10000 took 0.637s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8524 of 10000 took 0.653s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8525 of 10000 took 0.637s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t49.83 %\n",
            "Epoch 8526 of 10000 took 0.634s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 8527 of 10000 took 0.656s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 8528 of 10000 took 0.656s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 8529 of 10000 took 0.641s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8530 of 10000 took 0.648s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 8531 of 10000 took 0.653s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 8532 of 10000 took 0.636s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t50.17 %\n",
            "Epoch 8533 of 10000 took 0.662s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 8534 of 10000 took 0.668s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8535 of 10000 took 0.640s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8536 of 10000 took 0.650s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 8537 of 10000 took 0.632s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8538 of 10000 took 0.641s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 8539 of 10000 took 0.649s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 8540 of 10000 took 0.626s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 8541 of 10000 took 0.639s\n",
            "  training accuracy:\t\t77.91 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8542 of 10000 took 0.631s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8543 of 10000 took 0.650s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8544 of 10000 took 0.648s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t49.83 %\n",
            "Epoch 8545 of 10000 took 0.681s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8546 of 10000 took 0.633s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 8547 of 10000 took 0.664s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8548 of 10000 took 0.668s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8549 of 10000 took 0.658s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8550 of 10000 took 0.641s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 8551 of 10000 took 0.663s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8552 of 10000 took 0.641s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 8553 of 10000 took 0.658s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 8554 of 10000 took 0.671s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8555 of 10000 took 0.660s\n",
            "  training accuracy:\t\t80.33 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8556 of 10000 took 0.655s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t37.72 %\n",
            "Epoch 8557 of 10000 took 0.664s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 8558 of 10000 took 0.672s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8559 of 10000 took 0.654s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8560 of 10000 took 0.665s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8561 of 10000 took 0.649s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 8562 of 10000 took 0.643s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8563 of 10000 took 0.676s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8564 of 10000 took 0.668s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 8565 of 10000 took 0.665s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t26.30 %\n",
            "Epoch 8566 of 10000 took 0.687s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 8567 of 10000 took 0.676s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8568 of 10000 took 0.671s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 8569 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 8570 of 10000 took 0.674s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 8571 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8572 of 10000 took 0.667s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 8573 of 10000 took 0.659s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8574 of 10000 took 0.657s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 8575 of 10000 took 0.686s\n",
            "  training accuracy:\t\t80.93 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8576 of 10000 took 0.647s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 8577 of 10000 took 0.666s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 8578 of 10000 took 0.673s\n",
            "  training accuracy:\t\t80.41 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 8579 of 10000 took 0.657s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 8580 of 10000 took 0.680s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8581 of 10000 took 0.674s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 8582 of 10000 took 0.683s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8583 of 10000 took 0.669s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 8584 of 10000 took 0.669s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 8585 of 10000 took 0.666s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8586 of 10000 took 0.671s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8587 of 10000 took 0.662s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8588 of 10000 took 0.680s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 8589 of 10000 took 0.665s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 8590 of 10000 took 0.678s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8591 of 10000 took 0.665s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t37.37 %\n",
            "Epoch 8592 of 10000 took 0.642s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8593 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 8594 of 10000 took 0.676s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8595 of 10000 took 0.678s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8596 of 10000 took 0.678s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 8597 of 10000 took 0.674s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t38.06 %\n",
            "Epoch 8598 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8599 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8600 of 10000 took 0.669s\n",
            "  training accuracy:\t\t77.65 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 8601 of 10000 took 0.665s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 8602 of 10000 took 0.662s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8603 of 10000 took 0.683s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 8604 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8605 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8606 of 10000 took 0.668s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t34.95 %\n",
            "Epoch 8607 of 10000 took 0.681s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8608 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8609 of 10000 took 0.664s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8610 of 10000 took 0.685s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8611 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 8612 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 8613 of 10000 took 0.661s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8614 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8615 of 10000 took 0.674s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 8616 of 10000 took 0.668s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8617 of 10000 took 0.697s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8618 of 10000 took 0.672s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t35.29 %\n",
            "Epoch 8619 of 10000 took 0.670s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8620 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 8621 of 10000 took 0.671s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8622 of 10000 took 0.661s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t31.14 %\n",
            "Epoch 8623 of 10000 took 0.671s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t29.07 %\n",
            "Epoch 8624 of 10000 took 0.671s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8625 of 10000 took 0.670s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8626 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t51.90 %\n",
            "Epoch 8627 of 10000 took 0.654s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t50.87 %\n",
            "Epoch 8628 of 10000 took 0.671s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8629 of 10000 took 0.677s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 8630 of 10000 took 0.664s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 8631 of 10000 took 0.671s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8632 of 10000 took 0.673s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 8633 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 8634 of 10000 took 0.679s\n",
            "  training accuracy:\t\t80.50 %\n",
            "  test accuracy:    \t\t37.37 %\n",
            "Epoch 8635 of 10000 took 0.692s\n",
            "  training accuracy:\t\t77.83 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8636 of 10000 took 0.664s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8637 of 10000 took 0.706s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 8638 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8639 of 10000 took 0.678s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8640 of 10000 took 0.684s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 8641 of 10000 took 0.723s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 8642 of 10000 took 0.672s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8643 of 10000 took 0.685s\n",
            "  training accuracy:\t\t80.50 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 8644 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8645 of 10000 took 0.675s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8646 of 10000 took 0.683s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8647 of 10000 took 0.682s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t28.72 %\n",
            "Epoch 8648 of 10000 took 0.672s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 8649 of 10000 took 0.674s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8650 of 10000 took 0.683s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8651 of 10000 took 0.680s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8652 of 10000 took 0.681s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8653 of 10000 took 0.675s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 8654 of 10000 took 0.691s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 8655 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 8656 of 10000 took 0.680s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8657 of 10000 took 0.679s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 8658 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 8659 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 8660 of 10000 took 0.685s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8661 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 8662 of 10000 took 0.663s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 8663 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8664 of 10000 took 0.707s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 8665 of 10000 took 0.689s\n",
            "  training accuracy:\t\t80.50 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8666 of 10000 took 0.673s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t28.37 %\n",
            "Epoch 8667 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 8668 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t52.94 %\n",
            "Epoch 8669 of 10000 took 0.680s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8670 of 10000 took 0.668s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 8671 of 10000 took 0.690s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8672 of 10000 took 0.670s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 8673 of 10000 took 0.670s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8674 of 10000 took 0.738s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 8675 of 10000 took 0.683s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8676 of 10000 took 0.673s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 8677 of 10000 took 0.726s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 8678 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8679 of 10000 took 0.672s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8680 of 10000 took 0.711s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8681 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 8682 of 10000 took 0.679s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 8683 of 10000 took 0.690s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8684 of 10000 took 0.684s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8685 of 10000 took 0.683s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 8686 of 10000 took 0.702s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8687 of 10000 took 0.689s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t33.22 %\n",
            "Epoch 8688 of 10000 took 0.684s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 8689 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 8690 of 10000 took 0.680s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 8691 of 10000 took 0.678s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8692 of 10000 took 0.674s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 8693 of 10000 took 0.683s\n",
            "  training accuracy:\t\t78.00 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 8694 of 10000 took 0.670s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8695 of 10000 took 0.699s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8696 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8697 of 10000 took 0.677s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 8698 of 10000 took 0.699s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8699 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t38.75 %\n",
            "Epoch 8700 of 10000 took 0.681s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8701 of 10000 took 0.687s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 8702 of 10000 took 0.666s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t28.72 %\n",
            "Epoch 8703 of 10000 took 0.680s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8704 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8705 of 10000 took 0.708s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8706 of 10000 took 0.673s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 8707 of 10000 took 0.682s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t31.83 %\n",
            "Epoch 8708 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t28.72 %\n",
            "Epoch 8709 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 8710 of 10000 took 0.698s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8711 of 10000 took 0.700s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 8712 of 10000 took 0.675s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 8713 of 10000 took 0.715s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8714 of 10000 took 0.695s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8715 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8716 of 10000 took 0.702s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 8717 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 8718 of 10000 took 0.676s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 8719 of 10000 took 0.722s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 8720 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8721 of 10000 took 0.684s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8722 of 10000 took 0.684s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8723 of 10000 took 0.688s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8724 of 10000 took 0.662s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8725 of 10000 took 0.697s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8726 of 10000 took 0.687s\n",
            "  training accuracy:\t\t78.00 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 8727 of 10000 took 0.693s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8728 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t49.13 %\n",
            "Epoch 8729 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 8730 of 10000 took 0.676s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 8731 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8732 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8733 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8734 of 10000 took 0.705s\n",
            "  training accuracy:\t\t80.41 %\n",
            "  test accuracy:    \t\t28.72 %\n",
            "Epoch 8735 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8736 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8737 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t29.76 %\n",
            "Epoch 8738 of 10000 took 0.684s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t32.18 %\n",
            "Epoch 8739 of 10000 took 0.678s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8740 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8741 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 8742 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8743 of 10000 took 0.701s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8744 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8745 of 10000 took 0.671s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t50.87 %\n",
            "Epoch 8746 of 10000 took 0.716s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8747 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t53.29 %\n",
            "Epoch 8748 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 8749 of 10000 took 0.710s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8750 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8751 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t52.60 %\n",
            "Epoch 8752 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 8753 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t28.72 %\n",
            "Epoch 8754 of 10000 took 0.673s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t50.17 %\n",
            "Epoch 8755 of 10000 took 0.715s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8756 of 10000 took 0.703s\n",
            "  training accuracy:\t\t77.57 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8757 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t50.87 %\n",
            "Epoch 8758 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8759 of 10000 took 0.684s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t38.06 %\n",
            "Epoch 8760 of 10000 took 0.688s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 8761 of 10000 took 0.679s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 8762 of 10000 took 0.673s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 8763 of 10000 took 0.672s\n",
            "  training accuracy:\t\t80.59 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8764 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8765 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 8766 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 8767 of 10000 took 0.699s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 8768 of 10000 took 0.691s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 8769 of 10000 took 0.670s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t32.53 %\n",
            "Epoch 8770 of 10000 took 0.698s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8771 of 10000 took 0.719s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t37.37 %\n",
            "Epoch 8772 of 10000 took 0.672s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 8773 of 10000 took 0.702s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 8774 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t49.13 %\n",
            "Epoch 8775 of 10000 took 0.678s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t37.37 %\n",
            "Epoch 8776 of 10000 took 0.710s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8777 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8778 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 8779 of 10000 took 0.703s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 8780 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 8781 of 10000 took 0.699s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t38.06 %\n",
            "Epoch 8782 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t51.56 %\n",
            "Epoch 8783 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8784 of 10000 took 0.687s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 8785 of 10000 took 0.708s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8786 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8787 of 10000 took 0.681s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 8788 of 10000 took 0.702s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 8789 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t53.63 %\n",
            "Epoch 8790 of 10000 took 0.710s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 8791 of 10000 took 0.702s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t49.48 %\n",
            "Epoch 8792 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 8793 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 8794 of 10000 took 0.706s\n",
            "  training accuracy:\t\t80.41 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8795 of 10000 took 0.732s\n",
            "  training accuracy:\t\t77.48 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8796 of 10000 took 0.693s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t28.37 %\n",
            "Epoch 8797 of 10000 took 0.719s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 8798 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8799 of 10000 took 0.689s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8800 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t52.25 %\n",
            "Epoch 8801 of 10000 took 0.690s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t50.52 %\n",
            "Epoch 8802 of 10000 took 0.677s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t50.52 %\n",
            "Epoch 8803 of 10000 took 0.701s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 8804 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8805 of 10000 took 0.684s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 8806 of 10000 took 0.708s\n",
            "  training accuracy:\t\t77.74 %\n",
            "  test accuracy:    \t\t50.52 %\n",
            "Epoch 8807 of 10000 took 0.719s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 8808 of 10000 took 0.683s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 8809 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 8810 of 10000 took 0.683s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8811 of 10000 took 0.681s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 8812 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t50.17 %\n",
            "Epoch 8813 of 10000 took 0.682s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 8814 of 10000 took 0.694s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8815 of 10000 took 0.700s\n",
            "  training accuracy:\t\t77.74 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8816 of 10000 took 0.680s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 8817 of 10000 took 0.691s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t49.83 %\n",
            "Epoch 8818 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t49.83 %\n",
            "Epoch 8819 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 8820 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8821 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8822 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8823 of 10000 took 0.708s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8824 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8825 of 10000 took 0.684s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 8826 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 8827 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8828 of 10000 took 0.693s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 8829 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 8830 of 10000 took 0.684s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 8831 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8832 of 10000 took 0.679s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t33.56 %\n",
            "Epoch 8833 of 10000 took 0.689s\n",
            "  training accuracy:\t\t77.83 %\n",
            "  test accuracy:    \t\t49.48 %\n",
            "Epoch 8834 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 8835 of 10000 took 0.685s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t51.90 %\n",
            "Epoch 8836 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8837 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8838 of 10000 took 0.687s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 8839 of 10000 took 0.704s\n",
            "  training accuracy:\t\t77.74 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8840 of 10000 took 0.687s\n",
            "  training accuracy:\t\t77.74 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8841 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t49.83 %\n",
            "Epoch 8842 of 10000 took 0.664s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8843 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 8844 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8845 of 10000 took 0.710s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t50.52 %\n",
            "Epoch 8846 of 10000 took 0.712s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 8847 of 10000 took 0.690s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 8848 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8849 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t50.17 %\n",
            "Epoch 8850 of 10000 took 0.695s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8851 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 8852 of 10000 took 0.678s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8853 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t33.56 %\n",
            "Epoch 8854 of 10000 took 0.682s\n",
            "  training accuracy:\t\t77.91 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 8855 of 10000 took 0.681s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8856 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t26.99 %\n",
            "Epoch 8857 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t24.91 %\n",
            "Epoch 8858 of 10000 took 0.716s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 8859 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 8860 of 10000 took 0.718s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 8861 of 10000 took 0.672s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t26.30 %\n",
            "Epoch 8862 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8863 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8864 of 10000 took 0.682s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t50.17 %\n",
            "Epoch 8865 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8866 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 8867 of 10000 took 0.670s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 8868 of 10000 took 0.696s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t37.37 %\n",
            "Epoch 8869 of 10000 took 0.717s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8870 of 10000 took 0.674s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 8871 of 10000 took 0.713s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 8872 of 10000 took 0.678s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 8873 of 10000 took 0.681s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8874 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 8875 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 8876 of 10000 took 0.676s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 8877 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8878 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 8879 of 10000 took 0.700s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t52.25 %\n",
            "Epoch 8880 of 10000 took 0.708s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 8881 of 10000 took 0.709s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 8882 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 8883 of 10000 took 0.714s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 8884 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8885 of 10000 took 0.703s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8886 of 10000 took 0.689s\n",
            "  training accuracy:\t\t77.57 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8887 of 10000 took 0.711s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 8888 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8889 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 8890 of 10000 took 0.716s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8891 of 10000 took 0.684s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8892 of 10000 took 0.678s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 8893 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 8894 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t51.56 %\n",
            "Epoch 8895 of 10000 took 0.715s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t54.67 %\n",
            "Epoch 8896 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8897 of 10000 took 0.694s\n",
            "  training accuracy:\t\t78.00 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8898 of 10000 took 0.683s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 8899 of 10000 took 0.708s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 8900 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8901 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 8902 of 10000 took 0.686s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 8903 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8904 of 10000 took 0.691s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 8905 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8906 of 10000 took 0.697s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8907 of 10000 took 0.683s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 8908 of 10000 took 0.713s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 8909 of 10000 took 0.700s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 8910 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8911 of 10000 took 0.713s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 8912 of 10000 took 0.698s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8913 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8914 of 10000 took 0.713s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 8915 of 10000 took 0.694s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8916 of 10000 took 0.690s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 8917 of 10000 took 0.706s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8918 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8919 of 10000 took 0.700s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t33.22 %\n",
            "Epoch 8920 of 10000 took 0.710s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 8921 of 10000 took 0.700s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8922 of 10000 took 0.676s\n",
            "  training accuracy:\t\t80.33 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8923 of 10000 took 0.714s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 8924 of 10000 took 0.699s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 8925 of 10000 took 0.708s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 8926 of 10000 took 0.691s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 8927 of 10000 took 0.712s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 8928 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 8929 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8930 of 10000 took 0.718s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t34.95 %\n",
            "Epoch 8931 of 10000 took 0.698s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8932 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 8933 of 10000 took 0.705s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8934 of 10000 took 0.679s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8935 of 10000 took 0.695s\n",
            "  training accuracy:\t\t80.41 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8936 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8937 of 10000 took 0.687s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 8938 of 10000 took 0.692s\n",
            "  training accuracy:\t\t77.22 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8939 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8940 of 10000 took 0.722s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 8941 of 10000 took 0.710s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8942 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 8943 of 10000 took 0.703s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 8944 of 10000 took 0.689s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 8945 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8946 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t37.72 %\n",
            "Epoch 8947 of 10000 took 0.708s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t51.90 %\n",
            "Epoch 8948 of 10000 took 0.696s\n",
            "  training accuracy:\t\t80.33 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 8949 of 10000 took 0.690s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 8950 of 10000 took 0.732s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 8951 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 8952 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 8953 of 10000 took 0.697s\n",
            "  training accuracy:\t\t78.00 %\n",
            "  test accuracy:    \t\t52.25 %\n",
            "Epoch 8954 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8955 of 10000 took 0.696s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t52.60 %\n",
            "Epoch 8956 of 10000 took 0.720s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t38.75 %\n",
            "Epoch 8957 of 10000 took 0.706s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t50.17 %\n",
            "Epoch 8958 of 10000 took 0.691s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t51.21 %\n",
            "Epoch 8959 of 10000 took 0.733s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t52.60 %\n",
            "Epoch 8960 of 10000 took 0.708s\n",
            "  training accuracy:\t\t77.91 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 8961 of 10000 took 0.691s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 8962 of 10000 took 0.684s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t37.72 %\n",
            "Epoch 8963 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8964 of 10000 took 0.680s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 8965 of 10000 took 0.703s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8966 of 10000 took 0.692s\n",
            "  training accuracy:\t\t77.91 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8967 of 10000 took 0.680s\n",
            "  training accuracy:\t\t77.83 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 8968 of 10000 took 0.698s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8969 of 10000 took 0.715s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8970 of 10000 took 0.683s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t35.29 %\n",
            "Epoch 8971 of 10000 took 0.703s\n",
            "  training accuracy:\t\t80.50 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 8972 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8973 of 10000 took 0.683s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t35.29 %\n",
            "Epoch 8974 of 10000 took 0.698s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 8975 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 8976 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8977 of 10000 took 0.693s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8978 of 10000 took 0.708s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 8979 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 8980 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 8981 of 10000 took 0.720s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 8982 of 10000 took 0.675s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t29.41 %\n",
            "Epoch 8983 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8984 of 10000 took 0.709s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 8985 of 10000 took 0.716s\n",
            "  training accuracy:\t\t77.83 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 8986 of 10000 took 0.707s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 8987 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 8988 of 10000 took 0.687s\n",
            "  training accuracy:\t\t77.91 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 8989 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 8990 of 10000 took 0.694s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 8991 of 10000 took 0.714s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 8992 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 8993 of 10000 took 0.708s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 8994 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 8995 of 10000 took 0.711s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8996 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 8997 of 10000 took 0.705s\n",
            "  training accuracy:\t\t80.67 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 8998 of 10000 took 0.698s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 8999 of 10000 took 0.728s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9000 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9001 of 10000 took 0.697s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9002 of 10000 took 0.679s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t29.41 %\n",
            "Epoch 9003 of 10000 took 0.711s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9004 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9005 of 10000 took 0.685s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 9006 of 10000 took 0.717s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 9007 of 10000 took 0.697s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9008 of 10000 took 0.699s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 9009 of 10000 took 0.690s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9010 of 10000 took 0.710s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9011 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 9012 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9013 of 10000 took 0.713s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 9014 of 10000 took 0.702s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9015 of 10000 took 0.712s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 9016 of 10000 took 0.707s\n",
            "  training accuracy:\t\t77.48 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9017 of 10000 took 0.709s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9018 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t49.13 %\n",
            "Epoch 9019 of 10000 took 0.706s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9020 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9021 of 10000 took 0.691s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 9022 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9023 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9024 of 10000 took 0.708s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 9025 of 10000 took 0.712s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 9026 of 10000 took 0.688s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9027 of 10000 took 0.738s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 9028 of 10000 took 0.709s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 9029 of 10000 took 0.730s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9030 of 10000 took 0.735s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9031 of 10000 took 0.734s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 9032 of 10000 took 0.696s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9033 of 10000 took 0.694s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t38.75 %\n",
            "Epoch 9034 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 9035 of 10000 took 0.717s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t50.87 %\n",
            "Epoch 9036 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t49.83 %\n",
            "Epoch 9037 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9038 of 10000 took 0.706s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t49.13 %\n",
            "Epoch 9039 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9040 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9041 of 10000 took 0.716s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 9042 of 10000 took 0.687s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 9043 of 10000 took 0.699s\n",
            "  training accuracy:\t\t78.00 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9044 of 10000 took 0.699s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9045 of 10000 took 0.719s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t50.87 %\n",
            "Epoch 9046 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9047 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9048 of 10000 took 0.721s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 9049 of 10000 took 0.717s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9050 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9051 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9052 of 10000 took 0.681s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t49.13 %\n",
            "Epoch 9053 of 10000 took 0.711s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 9054 of 10000 took 0.764s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9055 of 10000 took 0.705s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 9056 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 9057 of 10000 took 0.720s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9058 of 10000 took 0.715s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t37.72 %\n",
            "Epoch 9059 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 9060 of 10000 took 0.705s\n",
            "  training accuracy:\t\t80.59 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9061 of 10000 took 0.716s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 9062 of 10000 took 0.686s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 9063 of 10000 took 0.713s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9064 of 10000 took 0.718s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9065 of 10000 took 0.699s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 9066 of 10000 took 0.707s\n",
            "  training accuracy:\t\t78.00 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9067 of 10000 took 0.741s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9068 of 10000 took 0.717s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 9069 of 10000 took 0.695s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 9070 of 10000 took 0.719s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 9071 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 9072 of 10000 took 0.678s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9073 of 10000 took 0.689s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 9074 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 9075 of 10000 took 0.690s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 9076 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9077 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 9078 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9079 of 10000 took 0.693s\n",
            "  training accuracy:\t\t77.91 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9080 of 10000 took 0.738s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 9081 of 10000 took 0.701s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9082 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9083 of 10000 took 0.679s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9084 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 9085 of 10000 took 0.698s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t55.02 %\n",
            "Epoch 9086 of 10000 took 0.684s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t37.37 %\n",
            "Epoch 9087 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9088 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9089 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t23.88 %\n",
            "Epoch 9090 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t31.14 %\n",
            "Epoch 9091 of 10000 took 0.678s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9092 of 10000 took 0.657s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t26.99 %\n",
            "Epoch 9093 of 10000 took 0.702s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t28.72 %\n",
            "Epoch 9094 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t31.83 %\n",
            "Epoch 9095 of 10000 took 0.672s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t51.56 %\n",
            "Epoch 9096 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9097 of 10000 took 0.679s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9098 of 10000 took 0.670s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9099 of 10000 took 0.708s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t31.14 %\n",
            "Epoch 9100 of 10000 took 0.681s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t28.37 %\n",
            "Epoch 9101 of 10000 took 0.678s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t24.22 %\n",
            "Epoch 9102 of 10000 took 0.665s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9103 of 10000 took 0.683s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 9104 of 10000 took 0.685s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9105 of 10000 took 0.703s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9106 of 10000 took 0.684s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 9107 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9108 of 10000 took 0.678s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 9109 of 10000 took 0.711s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9110 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9111 of 10000 took 0.696s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 9112 of 10000 took 0.683s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9113 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 9114 of 10000 took 0.703s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t33.91 %\n",
            "Epoch 9115 of 10000 took 0.711s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9116 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t31.49 %\n",
            "Epoch 9117 of 10000 took 0.707s\n",
            "  training accuracy:\t\t77.83 %\n",
            "  test accuracy:    \t\t27.34 %\n",
            "Epoch 9118 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t32.18 %\n",
            "Epoch 9119 of 10000 took 0.680s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t34.60 %\n",
            "Epoch 9120 of 10000 took 0.685s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 9121 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t26.99 %\n",
            "Epoch 9122 of 10000 took 0.670s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9123 of 10000 took 0.678s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 9124 of 10000 took 0.680s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 9125 of 10000 took 0.679s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 9126 of 10000 took 0.675s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 9127 of 10000 took 0.683s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 9128 of 10000 took 0.694s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t29.41 %\n",
            "Epoch 9129 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9130 of 10000 took 0.758s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t33.56 %\n",
            "Epoch 9131 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9132 of 10000 took 0.668s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t49.13 %\n",
            "Epoch 9133 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t33.56 %\n",
            "Epoch 9134 of 10000 took 0.682s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9135 of 10000 took 0.705s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 9136 of 10000 took 0.691s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9137 of 10000 took 0.675s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9138 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t29.07 %\n",
            "Epoch 9139 of 10000 took 0.694s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 9140 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 9141 of 10000 took 0.681s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t29.07 %\n",
            "Epoch 9142 of 10000 took 0.671s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t38.75 %\n",
            "Epoch 9143 of 10000 took 0.674s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9144 of 10000 took 0.701s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9145 of 10000 took 0.686s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t38.75 %\n",
            "Epoch 9146 of 10000 took 0.663s\n",
            "  training accuracy:\t\t77.65 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 9147 of 10000 took 0.695s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 9148 of 10000 took 0.690s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9149 of 10000 took 0.670s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9150 of 10000 took 0.714s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t25.95 %\n",
            "Epoch 9151 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9152 of 10000 took 0.663s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9153 of 10000 took 0.698s\n",
            "  training accuracy:\t\t78.00 %\n",
            "  test accuracy:    \t\t49.13 %\n",
            "Epoch 9154 of 10000 took 0.725s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 9155 of 10000 took 0.669s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 9156 of 10000 took 0.719s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t38.06 %\n",
            "Epoch 9157 of 10000 took 0.694s\n",
            "  training accuracy:\t\t77.74 %\n",
            "  test accuracy:    \t\t49.83 %\n",
            "Epoch 9158 of 10000 took 0.678s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t49.48 %\n",
            "Epoch 9159 of 10000 took 0.716s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 9160 of 10000 took 0.700s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9161 of 10000 took 0.683s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9162 of 10000 took 0.702s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 9163 of 10000 took 0.723s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9164 of 10000 took 0.679s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 9165 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9166 of 10000 took 0.719s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t34.26 %\n",
            "Epoch 9167 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9168 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 9169 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t27.68 %\n",
            "Epoch 9170 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t29.07 %\n",
            "Epoch 9171 of 10000 took 0.687s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 9172 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 9173 of 10000 took 0.695s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9174 of 10000 took 0.701s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9175 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9176 of 10000 took 0.709s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 9177 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t33.22 %\n",
            "Epoch 9178 of 10000 took 0.696s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9179 of 10000 took 0.742s\n",
            "  training accuracy:\t\t77.31 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9180 of 10000 took 0.708s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9181 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 9182 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9183 of 10000 took 0.699s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t28.72 %\n",
            "Epoch 9184 of 10000 took 0.711s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 9185 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9186 of 10000 took 0.709s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t29.07 %\n",
            "Epoch 9187 of 10000 took 0.724s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t34.60 %\n",
            "Epoch 9188 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t33.91 %\n",
            "Epoch 9189 of 10000 took 0.694s\n",
            "  training accuracy:\t\t77.74 %\n",
            "  test accuracy:    \t\t35.29 %\n",
            "Epoch 9190 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9191 of 10000 took 0.712s\n",
            "  training accuracy:\t\t77.31 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9192 of 10000 took 0.683s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9193 of 10000 took 0.686s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 9194 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t49.48 %\n",
            "Epoch 9195 of 10000 took 0.703s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 9196 of 10000 took 0.683s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t32.53 %\n",
            "Epoch 9197 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9198 of 10000 took 0.745s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9199 of 10000 took 0.693s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9200 of 10000 took 0.698s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9201 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9202 of 10000 took 0.686s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 9203 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t20.76 %\n",
            "Epoch 9204 of 10000 took 0.708s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t29.41 %\n",
            "Epoch 9205 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 9206 of 10000 took 0.714s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 9207 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t27.68 %\n",
            "Epoch 9208 of 10000 took 0.725s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t32.18 %\n",
            "Epoch 9209 of 10000 took 0.693s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t26.64 %\n",
            "Epoch 9210 of 10000 took 0.708s\n",
            "  training accuracy:\t\t78.00 %\n",
            "  test accuracy:    \t\t33.56 %\n",
            "Epoch 9211 of 10000 took 0.710s\n",
            "  training accuracy:\t\t80.33 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9212 of 10000 took 0.684s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 9213 of 10000 took 0.704s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t31.14 %\n",
            "Epoch 9214 of 10000 took 0.728s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t31.14 %\n",
            "Epoch 9215 of 10000 took 0.710s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 9216 of 10000 took 0.705s\n",
            "  training accuracy:\t\t77.91 %\n",
            "  test accuracy:    \t\t23.53 %\n",
            "Epoch 9217 of 10000 took 0.719s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t29.76 %\n",
            "Epoch 9218 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9219 of 10000 took 0.700s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9220 of 10000 took 0.740s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9221 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t50.52 %\n",
            "Epoch 9222 of 10000 took 0.679s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t27.68 %\n",
            "Epoch 9223 of 10000 took 0.722s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9224 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9225 of 10000 took 0.711s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t33.22 %\n",
            "Epoch 9226 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9227 of 10000 took 0.716s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t32.18 %\n",
            "Epoch 9228 of 10000 took 0.712s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t29.07 %\n",
            "Epoch 9229 of 10000 took 0.722s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t28.03 %\n",
            "Epoch 9230 of 10000 took 0.718s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 9231 of 10000 took 0.704s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t28.37 %\n",
            "Epoch 9232 of 10000 took 0.672s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t23.53 %\n",
            "Epoch 9233 of 10000 took 0.696s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t26.30 %\n",
            "Epoch 9234 of 10000 took 0.701s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t27.34 %\n",
            "Epoch 9235 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9236 of 10000 took 0.727s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t26.99 %\n",
            "Epoch 9237 of 10000 took 0.699s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9238 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9239 of 10000 took 0.723s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t24.91 %\n",
            "Epoch 9240 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9241 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t32.53 %\n",
            "Epoch 9242 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9243 of 10000 took 0.689s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t25.95 %\n",
            "Epoch 9244 of 10000 took 0.704s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t29.41 %\n",
            "Epoch 9245 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9246 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9247 of 10000 took 0.699s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t31.83 %\n",
            "Epoch 9248 of 10000 took 0.710s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t34.95 %\n",
            "Epoch 9249 of 10000 took 0.685s\n",
            "  training accuracy:\t\t77.57 %\n",
            "  test accuracy:    \t\t34.26 %\n",
            "Epoch 9250 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t38.75 %\n",
            "Epoch 9251 of 10000 took 0.744s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t34.95 %\n",
            "Epoch 9252 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 9253 of 10000 took 0.703s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9254 of 10000 took 0.723s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 9255 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9256 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9257 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9258 of 10000 took 0.713s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 9259 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t29.76 %\n",
            "Epoch 9260 of 10000 took 0.702s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t38.75 %\n",
            "Epoch 9261 of 10000 took 0.714s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t24.57 %\n",
            "Epoch 9262 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t23.53 %\n",
            "Epoch 9263 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 9264 of 10000 took 0.683s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9265 of 10000 took 0.740s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9266 of 10000 took 0.724s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t38.06 %\n",
            "Epoch 9267 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t25.95 %\n",
            "Epoch 9268 of 10000 took 0.713s\n",
            "  training accuracy:\t\t77.83 %\n",
            "  test accuracy:    \t\t23.88 %\n",
            "Epoch 9269 of 10000 took 0.700s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 9270 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9271 of 10000 took 0.720s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9272 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9273 of 10000 took 0.711s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9274 of 10000 took 0.710s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9275 of 10000 took 0.711s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t34.26 %\n",
            "Epoch 9276 of 10000 took 0.682s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t25.26 %\n",
            "Epoch 9277 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 9278 of 10000 took 0.715s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9279 of 10000 took 0.696s\n",
            "  training accuracy:\t\t77.83 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9280 of 10000 took 0.695s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t34.60 %\n",
            "Epoch 9281 of 10000 took 0.712s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9282 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9283 of 10000 took 0.702s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t22.84 %\n",
            "Epoch 9284 of 10000 took 0.720s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 9285 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9286 of 10000 took 0.712s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 9287 of 10000 took 0.736s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 9288 of 10000 took 0.696s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 9289 of 10000 took 0.702s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t28.03 %\n",
            "Epoch 9290 of 10000 took 0.702s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t34.60 %\n",
            "Epoch 9291 of 10000 took 0.718s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9292 of 10000 took 0.693s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9293 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t38.06 %\n",
            "Epoch 9294 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t34.60 %\n",
            "Epoch 9295 of 10000 took 0.699s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9296 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 9297 of 10000 took 0.712s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t27.68 %\n",
            "Epoch 9298 of 10000 took 0.716s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t27.68 %\n",
            "Epoch 9299 of 10000 took 0.703s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t24.22 %\n",
            "Epoch 9300 of 10000 took 0.716s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9301 of 10000 took 0.722s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9302 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 9303 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 9304 of 10000 took 0.703s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9305 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9306 of 10000 took 0.706s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9307 of 10000 took 0.689s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9308 of 10000 took 0.700s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 9309 of 10000 took 0.718s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 9310 of 10000 took 0.710s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9311 of 10000 took 0.693s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9312 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t28.03 %\n",
            "Epoch 9313 of 10000 took 0.719s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9314 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t37.72 %\n",
            "Epoch 9315 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9316 of 10000 took 0.725s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9317 of 10000 took 0.698s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 9318 of 10000 took 0.701s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9319 of 10000 took 0.719s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9320 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 9321 of 10000 took 0.700s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9322 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t26.99 %\n",
            "Epoch 9323 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 9324 of 10000 took 0.698s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 9325 of 10000 took 0.703s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t29.41 %\n",
            "Epoch 9326 of 10000 took 0.724s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9327 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9328 of 10000 took 0.727s\n",
            "  training accuracy:\t\t80.41 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 9329 of 10000 took 0.699s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t25.61 %\n",
            "Epoch 9330 of 10000 took 0.691s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 9331 of 10000 took 0.698s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t38.06 %\n",
            "Epoch 9332 of 10000 took 0.724s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 9333 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 9334 of 10000 took 0.718s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9335 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t27.34 %\n",
            "Epoch 9336 of 10000 took 0.689s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t29.76 %\n",
            "Epoch 9337 of 10000 took 0.703s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 9338 of 10000 took 0.723s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t54.33 %\n",
            "Epoch 9339 of 10000 took 0.689s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9340 of 10000 took 0.708s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9341 of 10000 took 0.725s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t35.29 %\n",
            "Epoch 9342 of 10000 took 0.687s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 9343 of 10000 took 0.698s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t38.06 %\n",
            "Epoch 9344 of 10000 took 0.744s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 9345 of 10000 took 0.715s\n",
            "  training accuracy:\t\t80.50 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 9346 of 10000 took 0.700s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9347 of 10000 took 0.710s\n",
            "  training accuracy:\t\t77.65 %\n",
            "  test accuracy:    \t\t32.53 %\n",
            "Epoch 9348 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 9349 of 10000 took 0.705s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t29.07 %\n",
            "Epoch 9350 of 10000 took 0.705s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t33.56 %\n",
            "Epoch 9351 of 10000 took 0.713s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 9352 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t25.95 %\n",
            "Epoch 9353 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t29.07 %\n",
            "Epoch 9354 of 10000 took 0.719s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 9355 of 10000 took 0.706s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t31.83 %\n",
            "Epoch 9356 of 10000 took 0.723s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9357 of 10000 took 0.712s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t51.21 %\n",
            "Epoch 9358 of 10000 took 0.712s\n",
            "  training accuracy:\t\t77.91 %\n",
            "  test accuracy:    \t\t29.07 %\n",
            "Epoch 9359 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9360 of 10000 took 0.708s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9361 of 10000 took 0.710s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9362 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 9363 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9364 of 10000 took 0.709s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t51.56 %\n",
            "Epoch 9365 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t50.52 %\n",
            "Epoch 9366 of 10000 took 0.697s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9367 of 10000 took 0.732s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9368 of 10000 took 0.739s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t50.17 %\n",
            "Epoch 9369 of 10000 took 0.701s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 9370 of 10000 took 0.726s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9371 of 10000 took 0.701s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 9372 of 10000 took 0.689s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9373 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t50.87 %\n",
            "Epoch 9374 of 10000 took 0.712s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9375 of 10000 took 0.702s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t28.03 %\n",
            "Epoch 9376 of 10000 took 0.715s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9377 of 10000 took 0.695s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 9378 of 10000 took 0.695s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 9379 of 10000 took 0.698s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t34.60 %\n",
            "Epoch 9380 of 10000 took 0.707s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t32.53 %\n",
            "Epoch 9381 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 9382 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 9383 of 10000 took 0.712s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t50.17 %\n",
            "Epoch 9384 of 10000 took 0.715s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t37.37 %\n",
            "Epoch 9385 of 10000 took 0.694s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9386 of 10000 took 0.729s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9387 of 10000 took 0.709s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t34.60 %\n",
            "Epoch 9388 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9389 of 10000 took 0.723s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t51.21 %\n",
            "Epoch 9390 of 10000 took 0.712s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9391 of 10000 took 0.706s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 9392 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t52.25 %\n",
            "Epoch 9393 of 10000 took 0.723s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t53.29 %\n",
            "Epoch 9394 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9395 of 10000 took 0.702s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 9396 of 10000 took 0.715s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t31.83 %\n",
            "Epoch 9397 of 10000 took 0.701s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9398 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9399 of 10000 took 0.730s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9400 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t27.68 %\n",
            "Epoch 9401 of 10000 took 0.745s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9402 of 10000 took 0.688s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 9403 of 10000 took 0.725s\n",
            "  training accuracy:\t\t77.48 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9404 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9405 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9406 of 10000 took 0.711s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9407 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9408 of 10000 took 0.709s\n",
            "  training accuracy:\t\t77.91 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9409 of 10000 took 0.729s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t49.48 %\n",
            "Epoch 9410 of 10000 took 0.703s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9411 of 10000 took 0.706s\n",
            "  training accuracy:\t\t77.39 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9412 of 10000 took 0.687s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9413 of 10000 took 0.713s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t31.14 %\n",
            "Epoch 9414 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 9415 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9416 of 10000 took 0.747s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9417 of 10000 took 0.715s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t29.41 %\n",
            "Epoch 9418 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 9419 of 10000 took 0.724s\n",
            "  training accuracy:\t\t80.50 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 9420 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9421 of 10000 took 0.698s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 9422 of 10000 took 0.719s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9423 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t28.03 %\n",
            "Epoch 9424 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t27.34 %\n",
            "Epoch 9425 of 10000 took 0.720s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 9426 of 10000 took 0.710s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9427 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9428 of 10000 took 0.728s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9429 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t38.75 %\n",
            "Epoch 9430 of 10000 took 0.704s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9431 of 10000 took 0.708s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t33.56 %\n",
            "Epoch 9432 of 10000 took 0.700s\n",
            "  training accuracy:\t\t80.33 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 9433 of 10000 took 0.686s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 9434 of 10000 took 0.747s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 9435 of 10000 took 0.700s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9436 of 10000 took 0.691s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t34.95 %\n",
            "Epoch 9437 of 10000 took 0.711s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 9438 of 10000 took 0.708s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9439 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 9440 of 10000 took 0.708s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 9441 of 10000 took 0.745s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9442 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9443 of 10000 took 0.712s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9444 of 10000 took 0.689s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t34.60 %\n",
            "Epoch 9445 of 10000 took 0.703s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t38.75 %\n",
            "Epoch 9446 of 10000 took 0.701s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t55.02 %\n",
            "Epoch 9447 of 10000 took 0.703s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9448 of 10000 took 0.698s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t49.13 %\n",
            "Epoch 9449 of 10000 took 0.695s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t35.29 %\n",
            "Epoch 9450 of 10000 took 0.724s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 9451 of 10000 took 0.688s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t26.64 %\n",
            "Epoch 9452 of 10000 took 0.683s\n",
            "  training accuracy:\t\t80.33 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9453 of 10000 took 0.701s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 9454 of 10000 took 0.722s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t26.30 %\n",
            "Epoch 9455 of 10000 took 0.705s\n",
            "  training accuracy:\t\t77.48 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9456 of 10000 took 0.704s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9457 of 10000 took 0.711s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9458 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 9459 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9460 of 10000 took 0.717s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9461 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t38.75 %\n",
            "Epoch 9462 of 10000 took 0.688s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 9463 of 10000 took 0.725s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9464 of 10000 took 0.714s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9465 of 10000 took 0.703s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 9466 of 10000 took 0.704s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t26.99 %\n",
            "Epoch 9467 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9468 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9469 of 10000 took 0.733s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9470 of 10000 took 0.683s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 9471 of 10000 took 0.693s\n",
            "  training accuracy:\t\t77.83 %\n",
            "  test accuracy:    \t\t28.37 %\n",
            "Epoch 9472 of 10000 took 0.676s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 9473 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 9474 of 10000 took 0.706s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t27.34 %\n",
            "Epoch 9475 of 10000 took 0.728s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9476 of 10000 took 0.693s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9477 of 10000 took 0.698s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9478 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9479 of 10000 took 0.712s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9480 of 10000 took 0.698s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9481 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9482 of 10000 took 0.686s\n",
            "  training accuracy:\t\t77.83 %\n",
            "  test accuracy:    \t\t34.95 %\n",
            "Epoch 9483 of 10000 took 0.696s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9484 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 9485 of 10000 took 0.724s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t52.60 %\n",
            "Epoch 9486 of 10000 took 0.698s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t34.60 %\n",
            "Epoch 9487 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9488 of 10000 took 0.729s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 9489 of 10000 took 0.713s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9490 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 9491 of 10000 took 0.706s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 9492 of 10000 took 0.680s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9493 of 10000 took 0.703s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9494 of 10000 took 0.703s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 9495 of 10000 took 0.718s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9496 of 10000 took 0.706s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9497 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 9498 of 10000 took 0.709s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 9499 of 10000 took 0.707s\n",
            "  training accuracy:\t\t80.50 %\n",
            "  test accuracy:    \t\t35.29 %\n",
            "Epoch 9500 of 10000 took 0.721s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9501 of 10000 took 0.712s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 9502 of 10000 took 0.728s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 9503 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9504 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9505 of 10000 took 0.693s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t55.71 %\n",
            "Epoch 9506 of 10000 took 0.694s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t38.75 %\n",
            "Epoch 9507 of 10000 took 0.688s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9508 of 10000 took 0.703s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9509 of 10000 took 0.696s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9510 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9511 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9512 of 10000 took 0.686s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t49.13 %\n",
            "Epoch 9513 of 10000 took 0.681s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 9514 of 10000 took 0.718s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t50.52 %\n",
            "Epoch 9515 of 10000 took 0.695s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t34.60 %\n",
            "Epoch 9516 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9517 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9518 of 10000 took 0.722s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 9519 of 10000 took 0.683s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9520 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9521 of 10000 took 0.716s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9522 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9523 of 10000 took 0.698s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9524 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t49.83 %\n",
            "Epoch 9525 of 10000 took 0.694s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t50.87 %\n",
            "Epoch 9526 of 10000 took 0.689s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9527 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9528 of 10000 took 0.710s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9529 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 9530 of 10000 took 0.707s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t51.90 %\n",
            "Epoch 9531 of 10000 took 0.711s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t50.87 %\n",
            "Epoch 9532 of 10000 took 0.670s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9533 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 9534 of 10000 took 0.714s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t31.83 %\n",
            "Epoch 9535 of 10000 took 0.721s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 9536 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 9537 of 10000 took 0.762s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9538 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9539 of 10000 took 0.687s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t49.13 %\n",
            "Epoch 9540 of 10000 took 0.722s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 9541 of 10000 took 0.703s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9542 of 10000 took 0.675s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9543 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9544 of 10000 took 0.714s\n",
            "  training accuracy:\t\t80.33 %\n",
            "  test accuracy:    \t\t37.37 %\n",
            "Epoch 9545 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t50.17 %\n",
            "Epoch 9546 of 10000 took 0.711s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t51.21 %\n",
            "Epoch 9547 of 10000 took 0.708s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t51.90 %\n",
            "Epoch 9548 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9549 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 9550 of 10000 took 0.713s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t34.60 %\n",
            "Epoch 9551 of 10000 took 0.694s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t31.49 %\n",
            "Epoch 9552 of 10000 took 0.680s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 9553 of 10000 took 0.729s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9554 of 10000 took 0.678s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t34.95 %\n",
            "Epoch 9555 of 10000 took 0.693s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 9556 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9557 of 10000 took 0.696s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9558 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t49.83 %\n",
            "Epoch 9559 of 10000 took 0.735s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 9560 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 9561 of 10000 took 0.680s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t35.29 %\n",
            "Epoch 9562 of 10000 took 0.684s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t29.41 %\n",
            "Epoch 9563 of 10000 took 0.681s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t33.22 %\n",
            "Epoch 9564 of 10000 took 0.712s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9565 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t49.48 %\n",
            "Epoch 9566 of 10000 took 0.701s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9567 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9568 of 10000 took 0.710s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 9569 of 10000 took 0.713s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 9570 of 10000 took 0.706s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 9571 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9572 of 10000 took 0.677s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t25.61 %\n",
            "Epoch 9573 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9574 of 10000 took 0.697s\n",
            "  training accuracy:\t\t78.00 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9575 of 10000 took 0.690s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9576 of 10000 took 0.731s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 9577 of 10000 took 0.693s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t28.37 %\n",
            "Epoch 9578 of 10000 took 0.698s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 9579 of 10000 took 0.707s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9580 of 10000 took 0.699s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 9581 of 10000 took 0.685s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 9582 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 9583 of 10000 took 0.672s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t31.14 %\n",
            "Epoch 9584 of 10000 took 0.690s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t49.83 %\n",
            "Epoch 9585 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t38.75 %\n",
            "Epoch 9586 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t51.90 %\n",
            "Epoch 9587 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 9588 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9589 of 10000 took 0.703s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9590 of 10000 took 0.700s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 9591 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t51.56 %\n",
            "Epoch 9592 of 10000 took 0.683s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t37.72 %\n",
            "Epoch 9593 of 10000 took 0.686s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t50.52 %\n",
            "Epoch 9594 of 10000 took 0.708s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9595 of 10000 took 0.706s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t28.03 %\n",
            "Epoch 9596 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t31.49 %\n",
            "Epoch 9597 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 9598 of 10000 took 0.703s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9599 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t29.41 %\n",
            "Epoch 9600 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9601 of 10000 took 0.718s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t29.76 %\n",
            "Epoch 9602 of 10000 took 0.671s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9603 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t44.98 %\n",
            "Epoch 9604 of 10000 took 0.715s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9605 of 10000 took 0.707s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9606 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t52.25 %\n",
            "Epoch 9607 of 10000 took 0.746s\n",
            "  training accuracy:\t\t78.00 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9608 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t52.25 %\n",
            "Epoch 9609 of 10000 took 0.684s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9610 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9611 of 10000 took 0.694s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9612 of 10000 took 0.673s\n",
            "  training accuracy:\t\t80.33 %\n",
            "  test accuracy:    \t\t38.75 %\n",
            "Epoch 9613 of 10000 took 0.713s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t28.72 %\n",
            "Epoch 9614 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t28.03 %\n",
            "Epoch 9615 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t33.22 %\n",
            "Epoch 9616 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9617 of 10000 took 0.715s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t31.14 %\n",
            "Epoch 9618 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t34.60 %\n",
            "Epoch 9619 of 10000 took 0.723s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 9620 of 10000 took 0.725s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9621 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9622 of 10000 took 0.689s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9623 of 10000 took 0.716s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9624 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t50.87 %\n",
            "Epoch 9625 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t49.48 %\n",
            "Epoch 9626 of 10000 took 0.739s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 9627 of 10000 took 0.690s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t33.56 %\n",
            "Epoch 9628 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9629 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 9630 of 10000 took 0.709s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t21.80 %\n",
            "Epoch 9631 of 10000 took 0.697s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9632 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t35.29 %\n",
            "Epoch 9633 of 10000 took 0.711s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9634 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t32.53 %\n",
            "Epoch 9635 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9636 of 10000 took 0.725s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9637 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9638 of 10000 took 0.711s\n",
            "  training accuracy:\t\t80.50 %\n",
            "  test accuracy:    \t\t31.14 %\n",
            "Epoch 9639 of 10000 took 0.686s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9640 of 10000 took 0.761s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t37.72 %\n",
            "Epoch 9641 of 10000 took 0.713s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 9642 of 10000 took 0.681s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9643 of 10000 took 0.720s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9644 of 10000 took 0.683s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9645 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t31.83 %\n",
            "Epoch 9646 of 10000 took 0.713s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t35.29 %\n",
            "Epoch 9647 of 10000 took 0.688s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t31.49 %\n",
            "Epoch 9648 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 9649 of 10000 took 0.726s\n",
            "  training accuracy:\t\t77.83 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 9650 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t50.87 %\n",
            "Epoch 9651 of 10000 took 0.686s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9652 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 9653 of 10000 took 0.687s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9654 of 10000 took 0.703s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9655 of 10000 took 0.731s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t53.98 %\n",
            "Epoch 9656 of 10000 took 0.693s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9657 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9658 of 10000 took 0.740s\n",
            "  training accuracy:\t\t80.41 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 9659 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9660 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9661 of 10000 took 0.710s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9662 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9663 of 10000 took 0.689s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t34.26 %\n",
            "Epoch 9664 of 10000 took 0.714s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 9665 of 10000 took 0.703s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t49.83 %\n",
            "Epoch 9666 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 9667 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9668 of 10000 took 0.709s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9669 of 10000 took 0.731s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 9670 of 10000 took 0.714s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t31.83 %\n",
            "Epoch 9671 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t26.64 %\n",
            "Epoch 9672 of 10000 took 0.719s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9673 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t27.34 %\n",
            "Epoch 9674 of 10000 took 0.720s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9675 of 10000 took 0.715s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9676 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t33.22 %\n",
            "Epoch 9677 of 10000 took 0.717s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9678 of 10000 took 0.703s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 9679 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 9680 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t34.95 %\n",
            "Epoch 9681 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 9682 of 10000 took 0.678s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 9683 of 10000 took 0.697s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t28.72 %\n",
            "Epoch 9684 of 10000 took 0.707s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 9685 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t33.56 %\n",
            "Epoch 9686 of 10000 took 0.701s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 9687 of 10000 took 0.717s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9688 of 10000 took 0.697s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 9689 of 10000 took 0.688s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t50.17 %\n",
            "Epoch 9690 of 10000 took 0.711s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t51.56 %\n",
            "Epoch 9691 of 10000 took 0.706s\n",
            "  training accuracy:\t\t78.00 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 9692 of 10000 took 0.690s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t35.29 %\n",
            "Epoch 9693 of 10000 took 0.718s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t51.56 %\n",
            "Epoch 9694 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t55.36 %\n",
            "Epoch 9695 of 10000 took 0.699s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t35.29 %\n",
            "Epoch 9696 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9697 of 10000 took 0.711s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9698 of 10000 took 0.710s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 9699 of 10000 took 0.704s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9700 of 10000 took 0.716s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 9701 of 10000 took 0.695s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9702 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t26.99 %\n",
            "Epoch 9703 of 10000 took 0.709s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 9704 of 10000 took 0.716s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t25.26 %\n",
            "Epoch 9705 of 10000 took 0.709s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9706 of 10000 took 0.725s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 9707 of 10000 took 0.710s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t31.49 %\n",
            "Epoch 9708 of 10000 took 0.708s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9709 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t33.22 %\n",
            "Epoch 9710 of 10000 took 0.716s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t33.56 %\n",
            "Epoch 9711 of 10000 took 0.703s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9712 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t31.49 %\n",
            "Epoch 9713 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t32.18 %\n",
            "Epoch 9714 of 10000 took 0.708s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 9715 of 10000 took 0.702s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t28.72 %\n",
            "Epoch 9716 of 10000 took 0.704s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9717 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t22.84 %\n",
            "Epoch 9718 of 10000 took 0.690s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t29.41 %\n",
            "Epoch 9719 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 9720 of 10000 took 0.704s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 9721 of 10000 took 0.704s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9722 of 10000 took 0.679s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9723 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9724 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t33.56 %\n",
            "Epoch 9725 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 9726 of 10000 took 0.727s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t29.76 %\n",
            "Epoch 9727 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 9728 of 10000 took 0.710s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t37.37 %\n",
            "Epoch 9729 of 10000 took 0.699s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 9730 of 10000 took 0.702s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t34.60 %\n",
            "Epoch 9731 of 10000 took 0.707s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t31.83 %\n",
            "Epoch 9732 of 10000 took 0.681s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t31.14 %\n",
            "Epoch 9733 of 10000 took 0.698s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 9734 of 10000 took 0.716s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 9735 of 10000 took 0.697s\n",
            "  training accuracy:\t\t80.76 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9736 of 10000 took 0.686s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 9737 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t34.26 %\n",
            "Epoch 9738 of 10000 took 0.723s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9739 of 10000 took 0.687s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t31.49 %\n",
            "Epoch 9740 of 10000 took 0.734s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t33.56 %\n",
            "Epoch 9741 of 10000 took 0.729s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 9742 of 10000 took 0.685s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t28.72 %\n",
            "Epoch 9743 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 9744 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 9745 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 9746 of 10000 took 0.703s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t29.41 %\n",
            "Epoch 9747 of 10000 took 0.711s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t32.53 %\n",
            "Epoch 9748 of 10000 took 0.698s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t31.14 %\n",
            "Epoch 9749 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t38.06 %\n",
            "Epoch 9750 of 10000 took 0.731s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9751 of 10000 took 0.705s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t49.48 %\n",
            "Epoch 9752 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 9753 of 10000 took 0.696s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9754 of 10000 took 0.721s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9755 of 10000 took 0.704s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t38.06 %\n",
            "Epoch 9756 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t51.21 %\n",
            "Epoch 9757 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t29.76 %\n",
            "Epoch 9758 of 10000 took 0.698s\n",
            "  training accuracy:\t\t80.41 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9759 of 10000 took 0.702s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t37.72 %\n",
            "Epoch 9760 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 9761 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 9762 of 10000 took 0.690s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9763 of 10000 took 0.753s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 9764 of 10000 took 0.705s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 9765 of 10000 took 0.715s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 9766 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9767 of 10000 took 0.727s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9768 of 10000 took 0.713s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 9769 of 10000 took 0.700s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 9770 of 10000 took 0.729s\n",
            "  training accuracy:\t\t80.41 %\n",
            "  test accuracy:    \t\t51.90 %\n",
            "Epoch 9771 of 10000 took 0.715s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t33.56 %\n",
            "Epoch 9772 of 10000 took 0.694s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9773 of 10000 took 0.740s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 9774 of 10000 took 0.711s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9775 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t33.56 %\n",
            "Epoch 9776 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9777 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t27.34 %\n",
            "Epoch 9778 of 10000 took 0.735s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t25.95 %\n",
            "Epoch 9779 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t31.49 %\n",
            "Epoch 9780 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9781 of 10000 took 0.706s\n",
            "  training accuracy:\t\t77.74 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9782 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t27.34 %\n",
            "Epoch 9783 of 10000 took 0.704s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 9784 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9785 of 10000 took 0.704s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t37.37 %\n",
            "Epoch 9786 of 10000 took 0.713s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t34.95 %\n",
            "Epoch 9787 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t27.68 %\n",
            "Epoch 9788 of 10000 took 0.720s\n",
            "  training accuracy:\t\t80.59 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 9789 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9790 of 10000 took 0.686s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9791 of 10000 took 0.699s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t50.17 %\n",
            "Epoch 9792 of 10000 took 0.682s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t32.53 %\n",
            "Epoch 9793 of 10000 took 0.701s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t33.22 %\n",
            "Epoch 9794 of 10000 took 0.711s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t49.83 %\n",
            "Epoch 9795 of 10000 took 0.714s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9796 of 10000 took 0.691s\n",
            "  training accuracy:\t\t78.00 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9797 of 10000 took 0.697s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9798 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t31.14 %\n",
            "Epoch 9799 of 10000 took 0.703s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 9800 of 10000 took 0.701s\n",
            "  training accuracy:\t\t77.91 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 9801 of 10000 took 0.713s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9802 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9803 of 10000 took 0.686s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t34.26 %\n",
            "Epoch 9804 of 10000 took 0.712s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t49.48 %\n",
            "Epoch 9805 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t24.91 %\n",
            "Epoch 9806 of 10000 took 0.709s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9807 of 10000 took 0.732s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9808 of 10000 took 0.708s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 9809 of 10000 took 0.689s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 9810 of 10000 took 0.699s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t31.49 %\n",
            "Epoch 9811 of 10000 took 0.707s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 9812 of 10000 took 0.700s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 9813 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 9814 of 10000 took 0.720s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t49.83 %\n",
            "Epoch 9815 of 10000 took 0.686s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9816 of 10000 took 0.695s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t51.90 %\n",
            "Epoch 9817 of 10000 took 0.730s\n",
            "  training accuracy:\t\t80.59 %\n",
            "  test accuracy:    \t\t52.60 %\n",
            "Epoch 9818 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 9819 of 10000 took 0.698s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t39.10 %\n",
            "Epoch 9820 of 10000 took 0.723s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 9821 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 9822 of 10000 took 0.684s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t50.17 %\n",
            "Epoch 9823 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t40.14 %\n",
            "Epoch 9824 of 10000 took 0.745s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9825 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 9826 of 10000 took 0.705s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t32.18 %\n",
            "Epoch 9827 of 10000 took 0.679s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9828 of 10000 took 0.708s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t50.17 %\n",
            "Epoch 9829 of 10000 took 0.707s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 9830 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 9831 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t51.56 %\n",
            "Epoch 9832 of 10000 took 0.673s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9833 of 10000 took 0.706s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9834 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t39.45 %\n",
            "Epoch 9835 of 10000 took 0.694s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t49.83 %\n",
            "Epoch 9836 of 10000 took 0.707s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t49.83 %\n",
            "Epoch 9837 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9838 of 10000 took 0.694s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t52.25 %\n",
            "Epoch 9839 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9840 of 10000 took 0.734s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 9841 of 10000 took 0.708s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 9842 of 10000 took 0.686s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t31.49 %\n",
            "Epoch 9843 of 10000 took 0.696s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 9844 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t25.61 %\n",
            "Epoch 9845 of 10000 took 0.702s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 9846 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t46.71 %\n",
            "Epoch 9847 of 10000 took 0.708s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9848 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9849 of 10000 took 0.707s\n",
            "  training accuracy:\t\t78.00 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 9850 of 10000 took 0.683s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9851 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9852 of 10000 took 0.674s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t49.13 %\n",
            "Epoch 9853 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 9854 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 9855 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 9856 of 10000 took 0.726s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t34.60 %\n",
            "Epoch 9857 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9858 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9859 of 10000 took 0.714s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9860 of 10000 took 0.695s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9861 of 10000 took 0.680s\n",
            "  training accuracy:\t\t80.76 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9862 of 10000 took 0.689s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t33.22 %\n",
            "Epoch 9863 of 10000 took 0.702s\n",
            "  training accuracy:\t\t77.91 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 9864 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 9865 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t48.79 %\n",
            "Epoch 9866 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t23.88 %\n",
            "Epoch 9867 of 10000 took 0.690s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t50.17 %\n",
            "Epoch 9868 of 10000 took 0.685s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t43.94 %\n",
            "Epoch 9869 of 10000 took 0.711s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 9870 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9871 of 10000 took 0.688s\n",
            "  training accuracy:\t\t80.33 %\n",
            "  test accuracy:    \t\t28.03 %\n",
            "Epoch 9872 of 10000 took 0.682s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t34.95 %\n",
            "Epoch 9873 of 10000 took 0.686s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 9874 of 10000 took 0.731s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t26.64 %\n",
            "Epoch 9875 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9876 of 10000 took 0.682s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t37.72 %\n",
            "Epoch 9877 of 10000 took 0.681s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t29.07 %\n",
            "Epoch 9878 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t47.75 %\n",
            "Epoch 9879 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 9880 of 10000 took 0.675s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t33.56 %\n",
            "Epoch 9881 of 10000 took 0.693s\n",
            "  training accuracy:\t\t77.65 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 9882 of 10000 took 0.680s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9883 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t34.26 %\n",
            "Epoch 9884 of 10000 took 0.697s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9885 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t31.14 %\n",
            "Epoch 9886 of 10000 took 0.677s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 9887 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t41.52 %\n",
            "Epoch 9888 of 10000 took 0.728s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 9889 of 10000 took 0.681s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t37.72 %\n",
            "Epoch 9890 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t42.21 %\n",
            "Epoch 9891 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t48.44 %\n",
            "Epoch 9892 of 10000 took 0.671s\n",
            "  training accuracy:\t\t80.85 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9893 of 10000 took 0.687s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9894 of 10000 took 0.710s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9895 of 10000 took 0.673s\n",
            "  training accuracy:\t\t77.39 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9896 of 10000 took 0.692s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 9897 of 10000 took 0.714s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t24.22 %\n",
            "Epoch 9898 of 10000 took 0.696s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t33.22 %\n",
            "Epoch 9899 of 10000 took 0.691s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 9900 of 10000 took 0.710s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 9901 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 9902 of 10000 took 0.674s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 9903 of 10000 took 0.683s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 9904 of 10000 took 0.704s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 9905 of 10000 took 0.674s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t41.87 %\n",
            "Epoch 9906 of 10000 took 0.670s\n",
            "  training accuracy:\t\t76.45 %\n",
            "  test accuracy:    \t\t38.06 %\n",
            "Epoch 9907 of 10000 took 0.684s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "Epoch 9908 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9909 of 10000 took 0.686s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t38.75 %\n",
            "Epoch 9910 of 10000 took 0.693s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9911 of 10000 took 0.694s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t38.41 %\n",
            "Epoch 9912 of 10000 took 0.674s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t44.64 %\n",
            "Epoch 9913 of 10000 took 0.678s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t30.80 %\n",
            "Epoch 9914 of 10000 took 0.690s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t42.56 %\n",
            "Epoch 9915 of 10000 took 0.672s\n",
            "  training accuracy:\t\t78.17 %\n",
            "  test accuracy:    \t\t44.29 %\n",
            "Epoch 9916 of 10000 took 0.690s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t29.07 %\n",
            "Epoch 9917 of 10000 took 0.706s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 9918 of 10000 took 0.681s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 9919 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 9920 of 10000 took 0.680s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 9921 of 10000 took 0.698s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t34.26 %\n",
            "Epoch 9922 of 10000 took 0.677s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 9923 of 10000 took 0.673s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9924 of 10000 took 0.724s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t50.87 %\n",
            "Epoch 9925 of 10000 took 0.687s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t45.67 %\n",
            "Epoch 9926 of 10000 took 0.699s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t50.87 %\n",
            "Epoch 9927 of 10000 took 0.684s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t46.02 %\n",
            "Epoch 9928 of 10000 took 0.675s\n",
            "  training accuracy:\t\t80.07 %\n",
            "  test accuracy:    \t\t35.64 %\n",
            "Epoch 9929 of 10000 took 0.693s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t37.72 %\n",
            "Epoch 9930 of 10000 took 0.688s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 9931 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 9932 of 10000 took 0.665s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 9933 of 10000 took 0.696s\n",
            "  training accuracy:\t\t77.65 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 9934 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t33.91 %\n",
            "Epoch 9935 of 10000 took 0.676s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t29.41 %\n",
            "Epoch 9936 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 9937 of 10000 took 0.720s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t31.14 %\n",
            "Epoch 9938 of 10000 took 0.676s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9939 of 10000 took 0.691s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 9940 of 10000 took 0.702s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t31.14 %\n",
            "Epoch 9941 of 10000 took 0.678s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t25.61 %\n",
            "Epoch 9942 of 10000 took 0.677s\n",
            "  training accuracy:\t\t79.90 %\n",
            "  test accuracy:    \t\t42.91 %\n",
            "Epoch 9943 of 10000 took 0.715s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t25.61 %\n",
            "Epoch 9944 of 10000 took 0.686s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 9945 of 10000 took 0.689s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 9946 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 9947 of 10000 took 0.703s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t36.68 %\n",
            "Epoch 9948 of 10000 took 0.678s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t28.37 %\n",
            "Epoch 9949 of 10000 took 0.714s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t30.10 %\n",
            "Epoch 9950 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 9951 of 10000 took 0.675s\n",
            "  training accuracy:\t\t78.34 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9952 of 10000 took 0.681s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t36.33 %\n",
            "Epoch 9953 of 10000 took 0.688s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t27.68 %\n",
            "Epoch 9954 of 10000 took 0.691s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t21.45 %\n",
            "Epoch 9955 of 10000 took 0.691s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t24.22 %\n",
            "Epoch 9956 of 10000 took 0.700s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t25.26 %\n",
            "Epoch 9957 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t34.26 %\n",
            "Epoch 9958 of 10000 took 0.691s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t37.02 %\n",
            "Epoch 9959 of 10000 took 0.681s\n",
            "  training accuracy:\t\t79.12 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9960 of 10000 took 0.721s\n",
            "  training accuracy:\t\t79.72 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9961 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.86 %\n",
            "  test accuracy:    \t\t25.61 %\n",
            "Epoch 9962 of 10000 took 0.675s\n",
            "  training accuracy:\t\t77.83 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9963 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.38 %\n",
            "  test accuracy:    \t\t41.18 %\n",
            "Epoch 9964 of 10000 took 0.725s\n",
            "  training accuracy:\t\t80.76 %\n",
            "  test accuracy:    \t\t37.37 %\n",
            "Epoch 9965 of 10000 took 0.687s\n",
            "  training accuracy:\t\t79.29 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 9966 of 10000 took 0.705s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t40.83 %\n",
            "Epoch 9967 of 10000 took 0.697s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t43.60 %\n",
            "Epoch 9968 of 10000 took 0.692s\n",
            "  training accuracy:\t\t77.57 %\n",
            "  test accuracy:    \t\t33.56 %\n",
            "Epoch 9969 of 10000 took 0.713s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t38.06 %\n",
            "Epoch 9970 of 10000 took 0.696s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t32.87 %\n",
            "Epoch 9971 of 10000 took 0.695s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9972 of 10000 took 0.709s\n",
            "  training accuracy:\t\t79.47 %\n",
            "  test accuracy:    \t\t35.99 %\n",
            "Epoch 9973 of 10000 took 0.693s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t25.95 %\n",
            "Epoch 9974 of 10000 took 0.693s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t35.29 %\n",
            "Epoch 9975 of 10000 took 0.704s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t34.26 %\n",
            "Epoch 9976 of 10000 took 0.718s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t43.25 %\n",
            "Epoch 9977 of 10000 took 0.731s\n",
            "  training accuracy:\t\t80.33 %\n",
            "  test accuracy:    \t\t25.26 %\n",
            "Epoch 9978 of 10000 took 0.680s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t38.06 %\n",
            "Epoch 9979 of 10000 took 0.730s\n",
            "  training accuracy:\t\t79.81 %\n",
            "  test accuracy:    \t\t47.40 %\n",
            "Epoch 9980 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.64 %\n",
            "  test accuracy:    \t\t24.22 %\n",
            "Epoch 9981 of 10000 took 0.684s\n",
            "  training accuracy:\t\t80.16 %\n",
            "  test accuracy:    \t\t35.29 %\n",
            "Epoch 9982 of 10000 took 0.679s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t39.79 %\n",
            "Epoch 9983 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t29.41 %\n",
            "Epoch 9984 of 10000 took 0.720s\n",
            "  training accuracy:\t\t78.95 %\n",
            "  test accuracy:    \t\t28.37 %\n",
            "Epoch 9985 of 10000 took 0.692s\n",
            "  training accuracy:\t\t78.69 %\n",
            "  test accuracy:    \t\t33.22 %\n",
            "Epoch 9986 of 10000 took 0.720s\n",
            "  training accuracy:\t\t79.98 %\n",
            "  test accuracy:    \t\t34.26 %\n",
            "Epoch 9987 of 10000 took 0.679s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t22.84 %\n",
            "Epoch 9988 of 10000 took 0.688s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t45.33 %\n",
            "Epoch 9989 of 10000 took 0.710s\n",
            "  training accuracy:\t\t78.26 %\n",
            "  test accuracy:    \t\t50.17 %\n",
            "Epoch 9990 of 10000 took 0.694s\n",
            "  training accuracy:\t\t78.52 %\n",
            "  test accuracy:    \t\t27.68 %\n",
            "Epoch 9991 of 10000 took 0.697s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t40.48 %\n",
            "Epoch 9992 of 10000 took 0.668s\n",
            "  training accuracy:\t\t78.08 %\n",
            "  test accuracy:    \t\t28.72 %\n",
            "Epoch 9993 of 10000 took 0.712s\n",
            "  training accuracy:\t\t80.24 %\n",
            "  test accuracy:    \t\t29.07 %\n",
            "Epoch 9994 of 10000 took 0.704s\n",
            "  training accuracy:\t\t78.77 %\n",
            "  test accuracy:    \t\t34.60 %\n",
            "Epoch 9995 of 10000 took 0.704s\n",
            "  training accuracy:\t\t77.74 %\n",
            "  test accuracy:    \t\t25.61 %\n",
            "Epoch 9996 of 10000 took 0.689s\n",
            "  training accuracy:\t\t79.21 %\n",
            "  test accuracy:    \t\t37.37 %\n",
            "Epoch 9997 of 10000 took 0.712s\n",
            "  training accuracy:\t\t78.60 %\n",
            "  test accuracy:    \t\t48.10 %\n",
            "Epoch 9998 of 10000 took 0.700s\n",
            "  training accuracy:\t\t79.03 %\n",
            "  test accuracy:    \t\t46.37 %\n",
            "Epoch 9999 of 10000 took 0.697s\n",
            "  training accuracy:\t\t78.43 %\n",
            "  test accuracy:    \t\t30.45 %\n",
            "Epoch 10000 of 10000 took 0.704s\n",
            "  training accuracy:\t\t79.55 %\n",
            "  test accuracy:    \t\t47.06 %\n",
            "done\n",
            "time cost 8337.500223398209 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmCk5wHmVnNY"
      },
      "source": [
        "Next you want to start reinforcement learning part of the model **using pg_su_net file as an input**\n",
        "\n",
        "\n",
        "\n",
        "> --pg_re.py - input for a pg_su_net_file from previous step \n",
        "\n",
        "\n",
        "```\n",
        "python launcher.py --exp_type=pg_re --pg_re=data/pg_su_net_file_20.pkl --simu_len=50 --num_ex=10 --ofile=data/pg_re\n",
        "```\n",
        "\n",
        "\n",
        "**ERROR IS CAUSED BY KEYBOARD INTERRUPT BECAUSE I DIDNT WANT TO WAIT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgY0wW6uXXqe",
        "outputId": "f97d9ba7-73b4-4cbb-8a97-a4118816b5b3",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "time_start=time.time()\n",
        "!python launcher.py --exp_type=pg_re --pg_re=data/pg_su_net_file_230.pkl --simu_len=50 --num_ex=10 --ofile=data/pg_re\n",
        "time_end=time.time()\n",
        "print('time cost',time_end-time_start,'s')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.59848484848484\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -190.28030303030306\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -305.3747252747252\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -441.62344322344296\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -166.0351981351982\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -240.04382284382285\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -223.49450549450538\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -234.4765567765567\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -103.53388278388275\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -201.54358974358985\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -189.82002997002994\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -269.6554445554445\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -268.97339327339336\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -330.550715950716\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -125.43088578088586\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -180.54673659673665\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -172.55757575757573\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -318.9402597402595\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 831\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15715\n",
            "MaxRew: \t -183.72335830835829\n",
            "MeanRew: \t -187.09548618048612 +- 76.72812994204146\n",
            "MeanSlowdown: \t 5.265610561609993\n",
            "MeanLen: \t 157.15 +- 18.703676109257238\n",
            "MeanEntropy \t 0.38198047971776755\n",
            "Elapsed time\t 33.6121461391449 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 832\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15802\n",
            "MaxRew: \t -183.8066916416916\n",
            "MeanRew: \t -189.17114668664664 +- 78.17212167883694\n",
            "MeanSlowdown: \t 5.333278028956163\n",
            "MeanLen: \t 158.02 +- 19.07300710428222\n",
            "MeanEntropy \t 0.38863841533307425\n",
            "Elapsed time\t 11.29332184791565 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 833\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15815\n",
            "MaxRew: \t -183.49644022644017\n",
            "MeanRew: \t -191.4252129537129 +- 77.43081336663919\n",
            "MeanSlowdown: \t 5.362773433626988\n",
            "MeanLen: \t 158.15 +- 20.51603031777834\n",
            "MeanEntropy \t 0.3977802613087048\n",
            "Elapsed time\t 11.600531339645386 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 834\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15952\n",
            "MaxRew: \t -184.9221911421911\n",
            "MeanRew: \t -194.38989577089572 +- 79.7323205122286\n",
            "MeanSlowdown: \t 5.42380459821922\n",
            "MeanLen: \t 159.52 +- 22.69558547383169\n",
            "MeanEntropy \t 0.395068184332637\n",
            "Elapsed time\t 11.478700876235962 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 835\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15766\n",
            "MaxRew: \t -183.52313519813518\n",
            "MeanRew: \t -186.24426390276386 +- 77.598328473865\n",
            "MeanSlowdown: \t 5.251769869800561\n",
            "MeanLen: \t 157.66 +- 18.537648178773917\n",
            "MeanEntropy \t 0.40109065797814086\n",
            "Elapsed time\t 11.134970664978027 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 836\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15957\n",
            "MaxRew: \t -183.3639127539127\n",
            "MeanRew: \t -187.11958624708626 +- 78.19085367682356\n",
            "MeanSlowdown: \t 5.264849832594065\n",
            "MeanLen: \t 159.57 +- 20.46179610884636\n",
            "MeanEntropy \t 0.4011418221651783\n",
            "Elapsed time\t 11.190454721450806 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 837\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15886\n",
            "MaxRew: \t -182.1961854811854\n",
            "MeanRew: \t -187.40171661671658 +- 78.67327101725625\n",
            "MeanSlowdown: \t 5.273059054650741\n",
            "MeanLen: \t 158.86 +- 19.34012409474148\n",
            "MeanEntropy \t 0.3858925335068619\n",
            "Elapsed time\t 11.142556190490723 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 838\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15826\n",
            "MaxRew: \t -183.75110389610387\n",
            "MeanRew: \t -186.72172743922744 +- 79.52086903748415\n",
            "MeanSlowdown: \t 5.264189840660429\n",
            "MeanLen: \t 158.26 +- 19.23570638162269\n",
            "MeanEntropy \t 0.3922607273789024\n",
            "Elapsed time\t 11.160062313079834 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 839\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15801\n",
            "MaxRew: \t -182.81024975024974\n",
            "MeanRew: \t -186.3521163836163 +- 77.89804846211656\n",
            "MeanSlowdown: \t 5.256014350233101\n",
            "MeanLen: \t 158.01 +- 19.441962349516057\n",
            "MeanEntropy \t 0.39762162382648497\n",
            "Elapsed time\t 11.360990285873413 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 840\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15794\n",
            "MaxRew: \t -184.62365800865797\n",
            "MeanRew: \t -186.7665621045621 +- 78.03186665846061\n",
            "MeanSlowdown: \t 5.264270924791254\n",
            "MeanLen: \t 157.94 +- 20.13197456783611\n",
            "MeanEntropy \t 0.3912752110193515\n",
            "Elapsed time\t 11.012864589691162 seconds\n",
            "-----------------\n",
            "Load on # 0 resource dimension is 1.167\n",
            "Load on # 1 resource dimension is 1.2995999999999999\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -230.43927738927744\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -455.2932400932398\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -261.095571095571\n",
            "---------- Random -----------\n",
            "total discount reward : \t -238.1874125874126\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.59848484848484\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -190.28030303030306\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -305.3747252747252\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -441.62344322344296\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -185.32610722610718\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -251.51969696969695\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -225.84688644688657\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -339.93516483516504\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -94.51483516483512\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -189.4717948717949\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -188.82002997002994\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -365.46573426573445\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -265.05031635031634\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -416.246853146853\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -125.09755244755254\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -177.38251748251753\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -259.02597402597405\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -306.83290043290026\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 841\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15837\n",
            "MaxRew: \t -183.196307026307\n",
            "MeanRew: \t -185.47291941391939 +- 78.18110474923843\n",
            "MeanSlowdown: \t 5.228010147373241\n",
            "MeanLen: \t 158.37 +- 20.402771870508182\n",
            "MeanEntropy \t 0.38369256104264154\n",
            "Elapsed time\t 35.74608516693115 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 842\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15631\n",
            "MaxRew: \t -183.50391275391272\n",
            "MeanRew: \t -185.90796969696967 +- 78.50616600498387\n",
            "MeanSlowdown: \t 5.237767096384843\n",
            "MeanLen: \t 156.31 +- 18.012603920588496\n",
            "MeanEntropy \t 0.3748773543917247\n",
            "Elapsed time\t 11.147639751434326 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 843\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15869\n",
            "MaxRew: \t -182.79591408591403\n",
            "MeanRew: \t -185.30927888777882 +- 77.99786615014513\n",
            "MeanSlowdown: \t 5.225841133385891\n",
            "MeanLen: \t 158.69 +- 19.718364536644515\n",
            "MeanEntropy \t 0.38706815383546017\n",
            "Elapsed time\t 11.306833505630493 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 844\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15719\n",
            "MaxRew: \t -184.28827339327336\n",
            "MeanRew: \t -185.5212239427239 +- 77.91389230544073\n",
            "MeanSlowdown: \t 5.228382554797113\n",
            "MeanLen: \t 157.19 +- 18.960324364314022\n",
            "MeanEntropy \t 0.3952950541164081\n",
            "Elapsed time\t 11.014515161514282 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 845\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15737\n",
            "MaxRew: \t -183.73385281385276\n",
            "MeanRew: \t -185.3807212787212 +- 77.70858428783015\n",
            "MeanSlowdown: \t 5.230395404784609\n",
            "MeanLen: \t 157.37 +- 19.508282856263904\n",
            "MeanEntropy \t 0.39149485915818866\n",
            "Elapsed time\t 10.966408967971802 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 846\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15688\n",
            "MaxRew: \t -183.7923143523143\n",
            "MeanRew: \t -186.35097502497493 +- 77.91163539232156\n",
            "MeanSlowdown: \t 5.250771458661705\n",
            "MeanLen: \t 156.88 +- 19.485009622784382\n",
            "MeanEntropy \t 0.393129566369454\n",
            "Elapsed time\t 11.009443998336792 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 847\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15518\n",
            "MaxRew: \t -184.12549617049612\n",
            "MeanRew: \t -185.42381118881116 +- 77.97651563263396\n",
            "MeanSlowdown: \t 5.229973643780462\n",
            "MeanLen: \t 155.18 +- 18.009652967228437\n",
            "MeanEntropy \t 0.37781402701183675\n",
            "Elapsed time\t 10.803048372268677 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 848\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15513\n",
            "MaxRew: \t -184.35713786213782\n",
            "MeanRew: \t -185.66376356976355 +- 77.86990557943761\n",
            "MeanSlowdown: \t 5.23313184352127\n",
            "MeanLen: \t 155.13 +- 19.312511488669724\n",
            "MeanEntropy \t 0.37400299945819965\n",
            "Elapsed time\t 10.652166843414307 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 849\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15711\n",
            "MaxRew: \t -183.86352314352308\n",
            "MeanRew: \t -185.65404761904756 +- 77.58746235434047\n",
            "MeanSlowdown: \t 5.2342828858174135\n",
            "MeanLen: \t 157.11 +- 18.479120650074233\n",
            "MeanEntropy \t 0.38735989749801136\n",
            "Elapsed time\t 11.40527629852295 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 850\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15625\n",
            "MaxRew: \t -182.5390942390942\n",
            "MeanRew: \t -186.38959224109217 +- 79.19142591691947\n",
            "MeanSlowdown: \t 5.25249604869912\n",
            "MeanLen: \t 156.25 +- 18.964374495353123\n",
            "MeanEntropy \t 0.3848878330549179\n",
            "Elapsed time\t 11.244331121444702 seconds\n",
            "-----------------\n",
            "Load on # 0 resource dimension is 1.167\n",
            "Load on # 1 resource dimension is 1.2995999999999999\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -229.005710955711\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -455.2932400932398\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -261.095571095571\n",
            "---------- Random -----------\n",
            "total discount reward : \t -255.58473193473196\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.59848484848484\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -190.28030303030306\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -315.9681318681318\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -403.19340659340645\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -175.49254079254072\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -196.46328671328666\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -181.8622710622712\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -242.32820512820496\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -93.682967032967\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -175.91318681318688\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -186.9866966366966\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -336.6630869130869\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -262.61478521478523\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -313.30925740925744\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -100.15349650349657\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -266.5733100233097\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -210.3857142857143\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -296.9584415584413\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 851\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15598\n",
            "MaxRew: \t -184.2069913419913\n",
            "MeanRew: \t -187.70060173160167 +- 78.78636440309936\n",
            "MeanSlowdown: \t 5.284189385768333\n",
            "MeanLen: \t 155.98 +- 18.428770984523087\n",
            "MeanEntropy \t 0.39274855400258907\n",
            "Elapsed time\t 35.30860424041748 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 852\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15689\n",
            "MaxRew: \t -184.54868797868795\n",
            "MeanRew: \t -186.30964518814514 +- 77.43643645839441\n",
            "MeanSlowdown: \t 5.250315568958913\n",
            "MeanLen: \t 156.89 +- 18.27998632384609\n",
            "MeanEntropy \t 0.4003940452030592\n",
            "Elapsed time\t 11.2300546169281 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 853\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15579\n",
            "MaxRew: \t -184.15332833832832\n",
            "MeanRew: \t -187.58780569430567 +- 78.01034953403612\n",
            "MeanSlowdown: \t 5.293902267240336\n",
            "MeanLen: \t 155.79 +- 18.828327063231082\n",
            "MeanEntropy \t 0.40000027743613875\n",
            "Elapsed time\t 10.911771297454834 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 854\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15735\n",
            "MaxRew: \t -183.83826839826835\n",
            "MeanRew: \t -187.09648634698632 +- 78.5632197262134\n",
            "MeanSlowdown: \t 5.257314486596332\n",
            "MeanLen: \t 157.35 +- 20.397732717142855\n",
            "MeanEntropy \t 0.3937631075400186\n",
            "Elapsed time\t 11.145116806030273 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 855\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15476\n",
            "MaxRew: \t -183.3074142524142\n",
            "MeanRew: \t -186.32623193473188 +- 77.48627084607776\n",
            "MeanSlowdown: \t 5.255242645012466\n",
            "MeanLen: \t 154.76 +- 17.66698616063306\n",
            "MeanEntropy \t 0.41741387673878544\n",
            "Elapsed time\t 10.675500392913818 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 856\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15625\n",
            "MaxRew: \t -183.271938061938\n",
            "MeanRew: \t -187.70210456210447 +- 77.76378008992056\n",
            "MeanSlowdown: \t 5.293324332480103\n",
            "MeanLen: \t 156.25 +- 17.710660631382446\n",
            "MeanEntropy \t 0.41854258517132104\n",
            "Elapsed time\t 11.02462100982666 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 857\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15524\n",
            "MaxRew: \t -184.25277888777885\n",
            "MeanRew: \t -185.23593473193472 +- 77.78195565714849\n",
            "MeanSlowdown: \t 5.222916157443012\n",
            "MeanLen: \t 155.24 +- 17.468325620963217\n",
            "MeanEntropy \t 0.4080663191784586\n",
            "Elapsed time\t 10.842467784881592 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 858\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15426\n",
            "MaxRew: \t -184.04042291042288\n",
            "MeanRew: \t -185.0284172494172 +- 78.02902417614521\n",
            "MeanSlowdown: \t 5.217476726172379\n",
            "MeanLen: \t 154.26 +- 17.368143251366853\n",
            "MeanEntropy \t 0.3955597322572976\n",
            "Elapsed time\t 11.166009902954102 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 859\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15499\n",
            "MaxRew: \t -184.08360972360967\n",
            "MeanRew: \t -185.65648917748914 +- 78.09082051408217\n",
            "MeanSlowdown: \t 5.232144277792742\n",
            "MeanLen: \t 154.99 +- 17.676252430874595\n",
            "MeanEntropy \t 0.39335672612835054\n",
            "Elapsed time\t 11.138153553009033 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 860\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15582\n",
            "MaxRew: \t -184.25277888777885\n",
            "MeanRew: \t -186.4820356310356 +- 78.62544378570877\n",
            "MeanSlowdown: \t 5.24850299145773\n",
            "MeanLen: \t 155.82 +- 18.980716530205072\n",
            "MeanEntropy \t 0.4014286272925192\n",
            "Elapsed time\t 11.199374437332153 seconds\n",
            "-----------------\n",
            "Load on # 0 resource dimension is 1.167\n",
            "Load on # 1 resource dimension is 1.2995999999999999\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -230.47424242424248\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -455.2932400932398\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -261.095571095571\n",
            "---------- Random -----------\n",
            "total discount reward : \t -238.1874125874126\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.59848484848484\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -190.28030303030306\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -305.8142857142857\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -441.62344322344296\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -166.0351981351982\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -240.04382284382285\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -252.30476190476176\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -234.4765567765567\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -97.41959706959702\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -201.54358974358985\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -189.82002997002994\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -269.6554445554445\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -267.6697302697303\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -330.550715950716\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -127.87960372960382\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -180.54673659673665\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -196.55887445887444\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -336.2437229437227\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 861\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15497\n",
            "MaxRew: \t -184.08606393606388\n",
            "MeanRew: \t -186.88020912420913 +- 80.15570628926523\n",
            "MeanSlowdown: \t 5.270655393673297\n",
            "MeanLen: \t 154.97 +- 17.836734566618407\n",
            "MeanEntropy \t 0.4075894008474456\n",
            "Elapsed time\t 34.36200714111328 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 862\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15581\n",
            "MaxRew: \t -184.0646903096903\n",
            "MeanRew: \t -187.81563270063262 +- 79.24439290708689\n",
            "MeanSlowdown: \t 5.297008073862294\n",
            "MeanLen: \t 155.81 +- 17.90010893821599\n",
            "MeanEntropy \t 0.41107923955402104\n",
            "Elapsed time\t 10.992391347885132 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 863\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 16037\n",
            "MaxRew: \t -183.023986013986\n",
            "MeanRew: \t -191.5479573759573 +- 81.37442189271333\n",
            "MeanSlowdown: \t 5.383863248116385\n",
            "MeanLen: \t 160.37 +- 19.27623147817021\n",
            "MeanEntropy \t 0.40509555294788285\n",
            "Elapsed time\t 11.272595405578613 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 864\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 16970\n",
            "MaxRew: \t -184.44991008991005\n",
            "MeanRew: \t -201.76080985680983 +- 82.5420265715746\n",
            "MeanSlowdown: \t 5.574734367936566\n",
            "MeanLen: \t 169.7 +- 21.76074447255884\n",
            "MeanEntropy \t 0.33714609752231484\n",
            "Elapsed time\t 11.664278030395508 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 865\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 16200\n",
            "MaxRew: \t -189.95434898434894\n",
            "MeanRew: \t -196.3127342657343 +- 78.35306634374537\n",
            "MeanSlowdown: \t 5.467916048561673\n",
            "MeanLen: \t 162.0 +- 23.01303978182804\n",
            "MeanEntropy \t 0.39988293620774074\n",
            "Elapsed time\t 11.353665590286255 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 866\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15883\n",
            "MaxRew: \t -183.96611222111216\n",
            "MeanRew: \t -190.41932434232433 +- 78.568395737673\n",
            "MeanSlowdown: \t 5.360987277796151\n",
            "MeanLen: \t 158.83 +- 18.4331521992306\n",
            "MeanEntropy \t 0.41195257635099153\n",
            "Elapsed time\t 10.981499910354614 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 867\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15517\n",
            "MaxRew: \t -184.32365800865796\n",
            "MeanRew: \t -185.73200083250077 +- 77.57533595980912\n",
            "MeanSlowdown: \t 5.233835787944403\n",
            "MeanLen: \t 155.17 +- 17.586389623797146\n",
            "MeanEntropy \t 0.4103216416291792\n",
            "Elapsed time\t 10.544937372207642 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 868\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15446\n",
            "MaxRew: \t -184.323658008658\n",
            "MeanRew: \t -185.43923509823503 +- 77.63953610084451\n",
            "MeanSlowdown: \t 5.22792049288213\n",
            "MeanLen: \t 154.46 +- 16.913556692783455\n",
            "MeanEntropy \t 0.41376442603008173\n",
            "Elapsed time\t 10.838531017303467 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 869\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15432\n",
            "MaxRew: \t -184.15654012654008\n",
            "MeanRew: \t -185.9562893772893 +- 77.26905751433469\n",
            "MeanSlowdown: \t 5.2436599774195685\n",
            "MeanLen: \t 154.32 +- 17.08793726580245\n",
            "MeanEntropy \t 0.41243494584178775\n",
            "Elapsed time\t 10.862972497940063 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 870\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15452\n",
            "MaxRew: \t -183.6424758574758\n",
            "MeanRew: \t -185.09880169830166 +- 77.83751562989046\n",
            "MeanSlowdown: \t 5.2142191663096105\n",
            "MeanLen: \t 154.52 +- 18.107169850642038\n",
            "MeanEntropy \t 0.41028185068492246\n",
            "Elapsed time\t 10.720166683197021 seconds\n",
            "-----------------\n",
            "Load on # 0 resource dimension is 1.167\n",
            "Load on # 1 resource dimension is 1.2995999999999999\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -234.012703962704\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -455.2932400932398\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -261.095571095571\n",
            "---------- Random -----------\n",
            "total discount reward : \t -238.1874125874126\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.59848484848484\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -190.28030303030306\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -305.3747252747252\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -441.62344322344296\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -176.90944055944055\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -251.51969696969695\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -212.58461538461546\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -291.28168498168515\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -97.18150183150178\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -156.8906593406594\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -188.82002997002994\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -243.90852480852482\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -268.58877788877794\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -313.09370629370613\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -117.65163170163177\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -211.15617715617716\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -279.74415584415567\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -272.4493506493504\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 871\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15482\n",
            "MaxRew: \t -183.30295204795203\n",
            "MeanRew: \t -186.66850233100223 +- 77.8105932375863\n",
            "MeanSlowdown: \t 5.253391797499398\n",
            "MeanLen: \t 154.82 +- 18.732527859314665\n",
            "MeanEntropy \t 0.42392762589585437\n",
            "Elapsed time\t 35.13123941421509 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 872\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15427\n",
            "MaxRew: \t -183.47383116883114\n",
            "MeanRew: \t -186.122109057609 +- 78.70124743099431\n",
            "MeanSlowdown: \t 5.2471134465307285\n",
            "MeanLen: \t 154.27 +- 18.014913266513386\n",
            "MeanEntropy \t 0.42680551082205115\n",
            "Elapsed time\t 20.906704425811768 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 873\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15484\n",
            "MaxRew: \t -183.80360972360967\n",
            "MeanRew: \t -185.34684865134864 +- 78.06856443046757\n",
            "MeanSlowdown: \t 5.221899508741614\n",
            "MeanLen: \t 154.84 +- 18.79293484264765\n",
            "MeanEntropy \t 0.41271822589328605\n",
            "Elapsed time\t 10.723891496658325 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 874\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15543\n",
            "MaxRew: \t -183.80360972360967\n",
            "MeanRew: \t -186.29008008658005 +- 78.37741663206623\n",
            "MeanSlowdown: \t 5.245702517869375\n",
            "MeanLen: \t 155.43 +- 19.774354603880248\n",
            "MeanEntropy \t 0.409295136613278\n",
            "Elapsed time\t 10.764062881469727 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 875\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15376\n",
            "MaxRew: \t -183.5990942390942\n",
            "MeanRew: \t -185.7216946386946 +- 78.08123930498412\n",
            "MeanSlowdown: \t 5.235797848162829\n",
            "MeanLen: \t 153.76 +- 17.851117612071242\n",
            "MeanEntropy \t 0.4286933803895078\n",
            "Elapsed time\t 10.659170866012573 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 876\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15444\n",
            "MaxRew: \t -184.13273060273053\n",
            "MeanRew: \t -187.67601648351643 +- 78.94344073038108\n",
            "MeanSlowdown: \t 5.285205576281579\n",
            "MeanLen: \t 154.44 +- 19.23503054325623\n",
            "MeanEntropy \t 0.40859941269670774\n",
            "Elapsed time\t 10.82736611366272 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 877\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15592\n",
            "MaxRew: \t -184.09392107892103\n",
            "MeanRew: \t -188.41982967032965 +- 78.01510982592278\n",
            "MeanSlowdown: \t 5.317383407312385\n",
            "MeanLen: \t 155.92 +- 19.254443642962006\n",
            "MeanEntropy \t 0.40597471453410333\n",
            "Elapsed time\t 11.001939535140991 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 878\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15638\n",
            "MaxRew: \t -184.13154012654007\n",
            "MeanRew: \t -187.1517319347319 +- 77.6912714836975\n",
            "MeanSlowdown: \t 5.269787160447752\n",
            "MeanLen: \t 156.38 +- 19.936790112753858\n",
            "MeanEntropy \t 0.3992223802721166\n",
            "Elapsed time\t 11.181322574615479 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 879\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15472\n",
            "MaxRew: \t -183.61653513153507\n",
            "MeanRew: \t -185.47906193806185 +- 77.83504328998838\n",
            "MeanSlowdown: \t 5.230318033302685\n",
            "MeanLen: \t 154.72 +- 18.68640147272877\n",
            "MeanEntropy \t 0.41218399194894756\n",
            "Elapsed time\t 10.827214002609253 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 880\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15475\n",
            "MaxRew: \t -184.1458258408258\n",
            "MeanRew: \t -185.45598667998672 +- 77.5238968487395\n",
            "MeanSlowdown: \t 5.226908746641473\n",
            "MeanLen: \t 154.75 +- 17.430648295459353\n",
            "MeanEntropy \t 0.4181151559662684\n",
            "Elapsed time\t 10.795897245407104 seconds\n",
            "-----------------\n",
            "Load on # 0 resource dimension is 1.167\n",
            "Load on # 1 resource dimension is 1.2995999999999999\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -249.02668997669002\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -455.2932400932398\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -261.095571095571\n",
            "---------- Random -----------\n",
            "total discount reward : \t -255.58473193473196\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.59848484848484\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -190.28030303030306\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -305.3747252747252\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -441.62344322344296\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -189.82610722610718\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -251.51969696969695\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -166.2776556776558\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -345.208424908425\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -102.2465201465201\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -186.41538461538468\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -354.7994005994008\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -311.88320013320026\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -253.58401598401608\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -410.6109890109891\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -130.7128205128206\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -211.15617715617716\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -162.73679653679653\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -273.71731601731585\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 881\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15449\n",
            "MaxRew: \t -183.6691475191475\n",
            "MeanRew: \t -185.67904961704954 +- 78.47459290720806\n",
            "MeanSlowdown: \t 5.233421975617029\n",
            "MeanLen: \t 154.49 +- 18.988678205709846\n",
            "MeanEntropy \t 0.40887723690599875\n",
            "Elapsed time\t 36.544912576675415 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 882\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15538\n",
            "MaxRew: \t -184.27777888777885\n",
            "MeanRew: \t -185.8182074592074 +- 77.80210734955998\n",
            "MeanSlowdown: \t 5.239545152592338\n",
            "MeanLen: \t 155.38 +- 18.320360258466533\n",
            "MeanEntropy \t 0.4247515606741916\n",
            "Elapsed time\t 10.764619588851929 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 883\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15521\n",
            "MaxRew: \t -183.78391441891438\n",
            "MeanRew: \t -185.46174425574424 +- 78.57592053056462\n",
            "MeanSlowdown: \t 5.232557953410226\n",
            "MeanLen: \t 155.21 +- 18.54146434346543\n",
            "MeanEntropy \t 0.41907073581841864\n",
            "Elapsed time\t 11.47152590751648 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 884\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15501\n",
            "MaxRew: \t -184.27958041958036\n",
            "MeanRew: \t -185.91430519480517 +- 77.73470153976622\n",
            "MeanSlowdown: \t 5.242674238779981\n",
            "MeanLen: \t 155.01 +- 18.664134054383556\n",
            "MeanEntropy \t 0.41270883818096743\n",
            "Elapsed time\t 10.802068710327148 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 885\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15651\n",
            "MaxRew: \t -184.02806027306022\n",
            "MeanRew: \t -187.38064851814852 +- 78.40648323321756\n",
            "MeanSlowdown: \t 5.2748077096070265\n",
            "MeanLen: \t 156.51 +- 19.315017473458315\n",
            "MeanEntropy \t 0.4018455720990063\n",
            "Elapsed time\t 11.105456829071045 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 886\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15453\n",
            "MaxRew: \t -183.77383116883112\n",
            "MeanRew: \t -185.94405944055944 +- 78.16696519671835\n",
            "MeanSlowdown: \t 5.239686732564185\n",
            "MeanLen: \t 154.53 +- 17.765390510765588\n",
            "MeanEntropy \t 0.42320293493476613\n",
            "Elapsed time\t 11.761631727218628 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 887\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15527\n",
            "MaxRew: \t -183.62668831168827\n",
            "MeanRew: \t -185.43946253746245 +- 77.7959762889927\n",
            "MeanSlowdown: \t 5.226953763703835\n",
            "MeanLen: \t 155.27 +- 18.321492843106427\n",
            "MeanEntropy \t 0.42931091939525495\n",
            "Elapsed time\t 11.585399389266968 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 888\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15471\n",
            "MaxRew: \t -184.12668664668658\n",
            "MeanRew: \t -185.98759690309686 +- 77.4070470581665\n",
            "MeanSlowdown: \t 5.239390959917276\n",
            "MeanLen: \t 154.71 +- 18.146236524414643\n",
            "MeanEntropy \t 0.4163078526476166\n",
            "Elapsed time\t 10.651139736175537 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 889\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15372\n",
            "MaxRew: \t -184.10360972360965\n",
            "MeanRew: \t -184.92553146853137 +- 77.8356100432384\n",
            "MeanSlowdown: \t 5.2155257454490185\n",
            "MeanLen: \t 153.72 +- 16.782776885843415\n",
            "MeanEntropy \t 0.42546847035658625\n",
            "Elapsed time\t 10.78083610534668 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 890\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15537\n",
            "MaxRew: \t -184.11075258075252\n",
            "MeanRew: \t -186.65643273393266 +- 77.4303033590895\n",
            "MeanSlowdown: \t 5.263682995988283\n",
            "MeanLen: \t 155.37 +- 18.599814515204177\n",
            "MeanEntropy \t 0.4225059436006579\n",
            "Elapsed time\t 10.87526822090149 seconds\n",
            "-----------------\n",
            "Load on # 0 resource dimension is 1.167\n",
            "Load on # 1 resource dimension is 1.2995999999999999\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -141.87016317016318\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -455.2932400932398\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -261.095571095571\n",
            "---------- Random -----------\n",
            "total discount reward : \t -239.51794871794866\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.68939393939394\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -170.68939393939394\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -315.9681318681318\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -366.1139194139193\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -191.2261072261072\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -226.05407925407923\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -173.1648351648353\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -246.8234432234431\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -113.20989010989005\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -210.9749084249085\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -143.96178821178808\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -276.4421911421912\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -265.9733932733933\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -417.9452880452882\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -132.91911421911428\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -229.32727272727274\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -177.5718614718615\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -251.05194805194813\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 891\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15367\n",
            "MaxRew: \t -183.97677822177818\n",
            "MeanRew: \t -185.63705944055934 +- 77.39169682409333\n",
            "MeanSlowdown: \t 5.234284229552772\n",
            "MeanLen: \t 153.67 +- 16.567471140762553\n",
            "MeanEntropy \t 0.4138618436887445\n",
            "Elapsed time\t 35.235918283462524 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 892\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15379\n",
            "MaxRew: \t -183.18755744255742\n",
            "MeanRew: \t -185.96320912420907 +- 77.9909959565295\n",
            "MeanSlowdown: \t 5.238073107546792\n",
            "MeanLen: \t 153.79 +- 18.053971862169277\n",
            "MeanEntropy \t 0.40779058898450626\n",
            "Elapsed time\t 11.095795154571533 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 893\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15512\n",
            "MaxRew: \t -183.44778221778216\n",
            "MeanRew: \t -186.84057958707953 +- 76.4137065037878\n",
            "MeanSlowdown: \t 5.2624929030192185\n",
            "MeanLen: \t 155.12 +- 18.765542891160912\n",
            "MeanEntropy \t 0.4004817359319919\n",
            "Elapsed time\t 10.815551042556763 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 894\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15589\n",
            "MaxRew: \t -182.8468231768231\n",
            "MeanRew: \t -186.05592540792534 +- 78.32303259127045\n",
            "MeanSlowdown: \t 5.249660415342234\n",
            "MeanLen: \t 155.89 +- 17.741981287330905\n",
            "MeanEntropy \t 0.3851313257793109\n",
            "Elapsed time\t 10.778674602508545 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 895\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15353\n",
            "MaxRew: \t -183.55541791541788\n",
            "MeanRew: \t -185.31834232434224 +- 78.7856464997569\n",
            "MeanSlowdown: \t 5.227376288484244\n",
            "MeanLen: \t 153.53 +- 17.020255579749676\n",
            "MeanEntropy \t 0.3931356031896309\n",
            "Elapsed time\t 10.59940791130066 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 896\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15394\n",
            "MaxRew: \t -184.27008658008654\n",
            "MeanRew: \t -186.18963852813846 +- 78.77696067069999\n",
            "MeanSlowdown: \t 5.251422767573335\n",
            "MeanLen: \t 153.94 +- 16.300196317836175\n",
            "MeanEntropy \t 0.4047371487743542\n",
            "Elapsed time\t 10.733372211456299 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 897\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15503\n",
            "MaxRew: \t -184.57109390609384\n",
            "MeanRew: \t -187.29427256077253 +- 79.65352243889866\n",
            "MeanSlowdown: \t 5.278944546118273\n",
            "MeanLen: \t 155.03 +- 19.08164301101978\n",
            "MeanEntropy \t 0.40557966261872097\n",
            "Elapsed time\t 10.797440767288208 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 898\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15322\n",
            "MaxRew: \t -184.39287046287043\n",
            "MeanRew: \t -186.45301298701295 +- 77.11363349869468\n",
            "MeanSlowdown: \t 5.257393813915553\n",
            "MeanLen: \t 153.22 +- 16.93019787244083\n",
            "MeanEntropy \t 0.40220528532699396\n",
            "Elapsed time\t 10.668802499771118 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 899\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15549\n",
            "MaxRew: \t -184.25472693972688\n",
            "MeanRew: \t -187.915262071262 +- 76.3693291276506\n",
            "MeanSlowdown: \t 5.299737176719274\n",
            "MeanLen: \t 155.49 +- 17.083029590795658\n",
            "MeanEntropy \t 0.3996510421389271\n",
            "Elapsed time\t 10.708479166030884 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 900\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15505\n",
            "MaxRew: \t -184.2493972693972\n",
            "MeanRew: \t -186.34642973692968 +- 76.78429974433256\n",
            "MeanSlowdown: \t 5.254591373389327\n",
            "MeanLen: \t 155.05 +- 17.46389131894722\n",
            "MeanEntropy \t 0.4045516339947865\n",
            "Elapsed time\t 10.785331964492798 seconds\n",
            "-----------------\n",
            "Load on # 0 resource dimension is 1.167\n",
            "Load on # 1 resource dimension is 1.2995999999999999\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -180.8905594405594\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -455.2932400932398\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -261.095571095571\n",
            "---------- Random -----------\n",
            "total discount reward : \t -239.51794871794866\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.68939393939394\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -170.68939393939394\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -315.9681318681318\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -366.1139194139193\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -199.58496503496494\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -226.05407925407923\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -167.15201465201477\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -246.8234432234431\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -98.16483516483513\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -210.9749084249085\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -150.85812520812505\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -269.36493506493514\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -257.8697302697302\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -340.9188811188811\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -117.65163170163177\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -196.7934731934732\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -169.96839826839823\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -266.7064935064934\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 901\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15489\n",
            "MaxRew: \t -184.50277888777885\n",
            "MeanRew: \t -185.67366783216775 +- 77.82917284245568\n",
            "MeanSlowdown: \t 5.2300764982078976\n",
            "MeanLen: \t 154.89 +- 16.737320574094287\n",
            "MeanEntropy \t 0.4080086796048013\n",
            "Elapsed time\t 33.988428831100464 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 902\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15448\n",
            "MaxRew: \t -182.7818914418914\n",
            "MeanRew: \t -184.9919433899433 +- 77.67997760680709\n",
            "MeanSlowdown: \t 5.218154582160264\n",
            "MeanLen: \t 154.48 +- 16.378937694490446\n",
            "MeanEntropy \t 0.40367207766165436\n",
            "Elapsed time\t 11.211687803268433 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 903\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15580\n",
            "MaxRew: \t -183.24607226107224\n",
            "MeanRew: \t -185.55883433233427 +- 78.8193927862821\n",
            "MeanSlowdown: \t 5.228883086007659\n",
            "MeanLen: \t 155.8 +- 17.675406643129882\n",
            "MeanEntropy \t 0.41531868787028514\n",
            "Elapsed time\t 11.251347303390503 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 904\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15433\n",
            "MaxRew: \t -184.5308924408924\n",
            "MeanRew: \t -186.23405061605058 +- 78.11063030686506\n",
            "MeanSlowdown: \t 5.252796389216844\n",
            "MeanLen: \t 154.33 +- 15.936784493742772\n",
            "MeanEntropy \t 0.3875556821998508\n",
            "Elapsed time\t 10.857883930206299 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 905\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15322\n",
            "MaxRew: \t -184.09637529137524\n",
            "MeanRew: \t -185.59072827172818 +- 78.62675179459531\n",
            "MeanSlowdown: \t 5.23522398056489\n",
            "MeanLen: \t 153.22 +- 17.928513602638674\n",
            "MeanEntropy \t 0.39915563141981003\n",
            "Elapsed time\t 10.812631368637085 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 906\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15332\n",
            "MaxRew: \t -184.0858441558441\n",
            "MeanRew: \t -186.0662863802863 +- 78.11873425983521\n",
            "MeanSlowdown: \t 5.248873285805105\n",
            "MeanLen: \t 153.32 +- 17.428643091187567\n",
            "MeanEntropy \t 0.41471287676062896\n",
            "Elapsed time\t 10.539301872253418 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 907\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15380\n",
            "MaxRew: \t -184.01963536463535\n",
            "MeanRew: \t -185.4016655011654 +- 77.51041464577331\n",
            "MeanSlowdown: \t 5.225309989981585\n",
            "MeanLen: \t 153.8 +- 17.480274597385478\n",
            "MeanEntropy \t 0.4108355374223849\n",
            "Elapsed time\t 10.82409119606018 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 908\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15346\n",
            "MaxRew: \t -183.7431335331335\n",
            "MeanRew: \t -185.38911072261072 +- 78.37626875423585\n",
            "MeanSlowdown: \t 5.2248620785736835\n",
            "MeanLen: \t 153.46 +- 17.358813323496513\n",
            "MeanEntropy \t 0.4089171088906512\n",
            "Elapsed time\t 10.480894327163696 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 909\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15448\n",
            "MaxRew: \t -183.7116816516816\n",
            "MeanRew: \t -185.86412037962026 +- 77.8135616158872\n",
            "MeanSlowdown: \t 5.236924096949694\n",
            "MeanLen: \t 154.48 +- 17.625254608090064\n",
            "MeanEntropy \t 0.40135288255886886\n",
            "Elapsed time\t 10.767308235168457 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 910\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15355\n",
            "MaxRew: \t -184.20360972360967\n",
            "MeanRew: \t -185.25141325341315 +- 78.53517503078251\n",
            "MeanSlowdown: \t 5.219592315155455\n",
            "MeanLen: \t 153.55 +- 17.45300833667365\n",
            "MeanEntropy \t 0.40529349812487797\n",
            "Elapsed time\t 10.37326455116272 seconds\n",
            "-----------------\n",
            "Load on # 0 resource dimension is 1.167\n",
            "Load on # 1 resource dimension is 1.2995999999999999\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -230.16655011655016\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -455.2932400932398\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -261.095571095571\n",
            "---------- Random -----------\n",
            "total discount reward : \t -238.1874125874126\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.59848484848484\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -190.28030303030306\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -305.8142857142857\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -441.62344322344296\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -165.11853146853153\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -240.04382284382285\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -198.3124542124541\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -234.4765567765567\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -131.8173992673992\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -201.54358974358985\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -154.85812520812505\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -269.6554445554445\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -262.61478521478523\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -330.550715950716\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -127.87960372960382\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -180.54673659673665\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -196.55887445887444\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -336.2437229437227\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 911\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15467\n",
            "MaxRew: \t -184.14113719613712\n",
            "MeanRew: \t -188.47080219780216 +- 81.96531289325942\n",
            "MeanSlowdown: \t 5.315283220142556\n",
            "MeanLen: \t 154.67 +- 16.500942397329915\n",
            "MeanEntropy \t 0.4094331171192982\n",
            "Elapsed time\t 34.225362062454224 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 912\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15381\n",
            "MaxRew: \t -183.18709956709952\n",
            "MeanRew: \t -185.42335381285378 +- 77.54538646310463\n",
            "MeanSlowdown: \t 5.230229160044501\n",
            "MeanLen: \t 153.81 +- 17.29259668181734\n",
            "MeanEntropy \t 0.41069149453426995\n",
            "Elapsed time\t 11.755626201629639 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 913\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15427\n",
            "MaxRew: \t -183.25248418248412\n",
            "MeanRew: \t -185.13287762237763 +- 77.92730119403305\n",
            "MeanSlowdown: \t 5.221731928109769\n",
            "MeanLen: \t 154.27 +- 17.116573839410737\n",
            "MeanEntropy \t 0.40620201050101185\n",
            "Elapsed time\t 10.601818561553955 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 914\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15288\n",
            "MaxRew: \t -183.25248418248412\n",
            "MeanRew: \t -185.13191508491505 +- 77.70021565774273\n",
            "MeanSlowdown: \t 5.2227210857324495\n",
            "MeanLen: \t 152.88 +- 17.100456134267297\n",
            "MeanEntropy \t 0.40459689130644577\n",
            "Elapsed time\t 10.629895448684692 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 915\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15269\n",
            "MaxRew: \t -184.25362637362633\n",
            "MeanRew: \t -185.22828704628708 +- 77.61509412498377\n",
            "MeanSlowdown: \t 5.224628174855448\n",
            "MeanLen: \t 152.69 +- 16.776587853315107\n",
            "MeanEntropy \t 0.4064079416726858\n",
            "Elapsed time\t 10.648230075836182 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 916\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15336\n",
            "MaxRew: \t -184.11944555444552\n",
            "MeanRew: \t -185.06751898101894 +- 77.86241198321594\n",
            "MeanSlowdown: \t 5.220319164736779\n",
            "MeanLen: \t 153.36 +- 16.962617722509695\n",
            "MeanEntropy \t 0.4108360302995963\n",
            "Elapsed time\t 10.690399408340454 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 917\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15378\n",
            "MaxRew: \t -184.4724675324675\n",
            "MeanRew: \t -186.2926050616051 +- 77.03879388229136\n",
            "MeanSlowdown: \t 5.254906627463446\n",
            "MeanLen: \t 153.78 +- 16.74131416585926\n",
            "MeanEntropy \t 0.40831218835538935\n",
            "Elapsed time\t 11.02409291267395 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 918\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15339\n",
            "MaxRew: \t -184.3690043290043\n",
            "MeanRew: \t -185.18316500166492 +- 77.92718523316697\n",
            "MeanSlowdown: \t 5.2237500141903555\n",
            "MeanLen: \t 153.39 +- 16.41578204046338\n",
            "MeanEntropy \t 0.3859863826285283\n",
            "Elapsed time\t 16.270142555236816 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 919\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15480\n",
            "MaxRew: \t -182.75508658008656\n",
            "MeanRew: \t -186.9151178821179 +- 76.38061240322251\n",
            "MeanSlowdown: \t 5.26561812748904\n",
            "MeanLen: \t 154.8 +- 18.68528833066271\n",
            "MeanEntropy \t 0.3745745293694214\n",
            "Elapsed time\t 11.600286722183228 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 920\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15425\n",
            "MaxRew: \t -183.60781218781216\n",
            "MeanRew: \t -185.43452414252405 +- 77.46191081288295\n",
            "MeanSlowdown: \t 5.222013415697626\n",
            "MeanLen: \t 154.25 +- 18.82093249549554\n",
            "MeanEntropy \t 0.3812202627039983\n",
            "Elapsed time\t 11.922365427017212 seconds\n",
            "-----------------\n",
            "Load on # 0 resource dimension is 1.167\n",
            "Load on # 1 resource dimension is 1.2995999999999999\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -200.65932400932402\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -455.2932400932398\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -261.095571095571\n",
            "---------- Random -----------\n",
            "total discount reward : \t -255.58473193473196\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.59848484848484\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -190.28030303030306\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -305.3747252747252\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -441.62344322344296\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -177.3261072261072\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -251.51969696969695\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -178.98021978021984\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -306.38827838827854\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -97.0148351648351\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -162.4190476190477\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -311.4210123210124\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -280.3205794205793\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -269.1272394272395\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -394.3753912753912\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -123.45536130536138\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -151.3015151515152\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -357.3874458874455\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -343.45281385281345\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 921\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15493\n",
            "MaxRew: \t -184.10360972360968\n",
            "MeanRew: \t -185.56797219447216 +- 77.9220542196108\n",
            "MeanSlowdown: \t 5.231529523158289\n",
            "MeanLen: \t 154.93 +- 17.506715854208633\n",
            "MeanEntropy \t 0.3822070516089981\n",
            "Elapsed time\t 36.80119585990906 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 922\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15407\n",
            "MaxRew: \t -184.01432400932396\n",
            "MeanRew: \t -185.87825391275385 +- 77.23716593450709\n",
            "MeanSlowdown: \t 5.238473498265995\n",
            "MeanLen: \t 154.07 +- 17.70833419607841\n",
            "MeanEntropy \t 0.3798762232371413\n",
            "Elapsed time\t 10.970778942108154 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 923\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15397\n",
            "MaxRew: \t -184.56015984015977\n",
            "MeanRew: \t -185.4595622710622 +- 77.7407022932864\n",
            "MeanSlowdown: \t 5.224330162302866\n",
            "MeanLen: \t 153.97 +- 18.152936401585283\n",
            "MeanEntropy \t 0.38835459657110855\n",
            "Elapsed time\t 10.729111433029175 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 924\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15387\n",
            "MaxRew: \t -184.136302031302\n",
            "MeanRew: \t -185.28822044622038 +- 77.85921999143905\n",
            "MeanSlowdown: \t 5.225882838752157\n",
            "MeanLen: \t 153.87 +- 16.808126010950776\n",
            "MeanEntropy \t 0.4010710493968604\n",
            "Elapsed time\t 10.783579111099243 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 925\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15289\n",
            "MaxRew: \t -184.06011155511152\n",
            "MeanRew: \t -185.03283949383942 +- 78.08816538651482\n",
            "MeanSlowdown: \t 5.219148531392849\n",
            "MeanLen: \t 152.89 +- 17.110753928450958\n",
            "MeanEntropy \t 0.39822020560190774\n",
            "Elapsed time\t 10.515618801116943 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 926\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15298\n",
            "MaxRew: \t -183.85672327672322\n",
            "MeanRew: \t -185.99860439560433 +- 77.48986751865878\n",
            "MeanSlowdown: \t 5.245564291727974\n",
            "MeanLen: \t 152.98 +- 17.442465422066917\n",
            "MeanEntropy \t 0.3972021112037924\n",
            "Elapsed time\t 10.686749696731567 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 927\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15426\n",
            "MaxRew: \t -183.5503629703629\n",
            "MeanRew: \t -186.97022910422908 +- 77.1109527523192\n",
            "MeanSlowdown: \t 5.274421109193836\n",
            "MeanLen: \t 154.26 +- 15.738881790012913\n",
            "MeanEntropy \t 0.4036830134905797\n",
            "Elapsed time\t 12.506240367889404 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 928\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15389\n",
            "MaxRew: \t -183.63584415584413\n",
            "MeanRew: \t -186.52994988344983 +- 78.63076680639668\n",
            "MeanSlowdown: \t 5.257422930490014\n",
            "MeanLen: \t 153.89 +- 17.12360651264797\n",
            "MeanEntropy \t 0.38732066288956596\n",
            "Elapsed time\t 11.21120834350586 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 929\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15843\n",
            "MaxRew: \t -184.03113719613714\n",
            "MeanRew: \t -197.16573176823167 +- 82.38357142499218\n",
            "MeanSlowdown: \t 5.54391853161084\n",
            "MeanLen: \t 158.43 +- 19.78396067525408\n",
            "MeanEntropy \t 0.3804069058370075\n",
            "Elapsed time\t 11.115829467773438 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 930\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15388\n",
            "MaxRew: \t -183.27286879786874\n",
            "MeanRew: \t -185.11481518481511 +- 77.9575954252432\n",
            "MeanSlowdown: \t 5.219182068286928\n",
            "MeanLen: \t 153.88 +- 16.89158370313453\n",
            "MeanEntropy \t 0.38273468776208525\n",
            "Elapsed time\t 10.998377084732056 seconds\n",
            "-----------------\n",
            "Load on # 0 resource dimension is 1.167\n",
            "Load on # 1 resource dimension is 1.2995999999999999\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -139.03111888111889\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -455.2932400932398\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -261.095571095571\n",
            "---------- Random -----------\n",
            "total discount reward : \t -265.4720279720278\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.68939393939394\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -170.68939393939394\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -330.66080586080585\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -366.1139194139193\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -188.13496503496495\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -221.54510489510483\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -175.3956043956045\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -337.11501831501863\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -101.86245421245415\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -223.40879120879129\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -354.7994005994008\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -278.9352813852814\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -263.1532467532468\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -330.54935064935074\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -126.90780885780894\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -195.63916083916087\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -172.78658008658005\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -286.7870129870128\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 931\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15348\n",
            "MaxRew: \t -183.89765734265728\n",
            "MeanRew: \t -184.96964918414912 +- 77.87970553823642\n",
            "MeanSlowdown: \t 5.218702145392487\n",
            "MeanLen: \t 153.48 +- 17.041408392500898\n",
            "MeanEntropy \t 0.3860524691388908\n",
            "Elapsed time\t 38.95832276344299 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 932\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15351\n",
            "MaxRew: \t -182.90495670995668\n",
            "MeanRew: \t -184.81051898101893 +- 77.76775370997107\n",
            "MeanSlowdown: \t 5.209657776589821\n",
            "MeanLen: \t 153.51 +- 17.588914122253257\n",
            "MeanEntropy \t 0.37983886513699894\n",
            "Elapsed time\t 10.864837884902954 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 933\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15281\n",
            "MaxRew: \t -183.12995670995667\n",
            "MeanRew: \t -185.1478334998335 +- 78.03084542008472\n",
            "MeanSlowdown: \t 5.223365190680531\n",
            "MeanLen: \t 152.81 +- 16.61426796461403\n",
            "MeanEntropy \t 0.3840405448717378\n",
            "Elapsed time\t 10.56697940826416 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 934\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15380\n",
            "MaxRew: \t -183.76917748917745\n",
            "MeanRew: \t -185.11800249750243 +- 78.13362391051027\n",
            "MeanSlowdown: \t 5.225371848795145\n",
            "MeanLen: \t 153.8 +- 17.41436188896969\n",
            "MeanEntropy \t 0.39299397458988605\n",
            "Elapsed time\t 11.027491569519043 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 935\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15352\n",
            "MaxRew: \t -184.1024192474192\n",
            "MeanRew: \t -186.1100244755244 +- 78.07515397727421\n",
            "MeanSlowdown: \t 5.245269160751106\n",
            "MeanLen: \t 153.52 +- 17.932361807637054\n",
            "MeanEntropy \t 0.3934568661817916\n",
            "Elapsed time\t 10.689711809158325 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 936\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15512\n",
            "MaxRew: \t -183.69152347652343\n",
            "MeanRew: \t -187.63196853146852 +- 82.38301355357211\n",
            "MeanSlowdown: \t 5.283886399125443\n",
            "MeanLen: \t 155.12 +- 18.596386745817053\n",
            "MeanEntropy \t 0.39636732187157775\n",
            "Elapsed time\t 10.790678024291992 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 937\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15659\n",
            "MaxRew: \t -182.32494838494833\n",
            "MeanRew: \t -188.65013636363636 +- 77.96848866099923\n",
            "MeanSlowdown: \t 5.299137214753301\n",
            "MeanLen: \t 156.59 +- 19.85955437566513\n",
            "MeanEntropy \t 0.38692857762447014\n",
            "Elapsed time\t 10.862923860549927 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 938\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15517\n",
            "MaxRew: \t -182.88584249084244\n",
            "MeanRew: \t -186.5383891108891 +- 79.89375519097423\n",
            "MeanSlowdown: \t 5.246226467557331\n",
            "MeanLen: \t 155.17 +- 18.21760412348451\n",
            "MeanEntropy \t 0.3898742190865072\n",
            "Elapsed time\t 10.746520042419434 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 939\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15334\n",
            "MaxRew: \t -183.98011655011652\n",
            "MeanRew: \t -187.57369497169498 +- 80.9454027059834\n",
            "MeanSlowdown: \t 5.284473563589287\n",
            "MeanLen: \t 153.34 +- 17.405872572209642\n",
            "MeanEntropy \t 0.4034703364067232\n",
            "Elapsed time\t 10.748603582382202 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 940\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15464\n",
            "MaxRew: \t -183.8795321345321\n",
            "MeanRew: \t -186.56162820512816 +- 79.64764459918212\n",
            "MeanSlowdown: \t 5.25751976674638\n",
            "MeanLen: \t 154.64 +- 18.004732711151252\n",
            "MeanEntropy \t 0.4089741313156578\n",
            "Elapsed time\t 11.03112506866455 seconds\n",
            "-----------------\n",
            "Load on # 0 resource dimension is 1.167\n",
            "Load on # 1 resource dimension is 1.2995999999999999\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -255.50874125874137\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -455.2932400932398\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -261.095571095571\n",
            "---------- Random -----------\n",
            "total discount reward : \t -250.92773892773894\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.68939393939394\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -170.68939393939394\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -310.4681318681319\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -366.1139194139193\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -246.16829836829828\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -236.38088578088568\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -164.08131868131878\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -257.6025641025639\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -118.55421245421242\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -147.8860805860806\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -290.5251581751582\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -377.20980685980714\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -263.05031635031634\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -358.4285048285048\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -150.8093240093241\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -197.067365967366\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -238.81688311688325\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -287.85281385281365\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 941\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15351\n",
            "MaxRew: \t -183.65323509823503\n",
            "MeanRew: \t -186.2298211788212 +- 77.98117277256407\n",
            "MeanSlowdown: \t 5.247564112505825\n",
            "MeanLen: \t 153.51 +- 17.391661795239695\n",
            "MeanEntropy \t 0.38217888477571105\n",
            "Elapsed time\t 34.19089341163635 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 942\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15327\n",
            "MaxRew: \t -184.66944555444553\n",
            "MeanRew: \t -186.85884182484176 +- 77.23450942260695\n",
            "MeanSlowdown: \t 5.269057145506009\n",
            "MeanLen: \t 153.27 +- 16.702607580853954\n",
            "MeanEntropy \t 0.3947334803225113\n",
            "Elapsed time\t 11.68064832687378 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 943\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15278\n",
            "MaxRew: \t -184.6694455544455\n",
            "MeanRew: \t -186.19798951048938 +- 77.41315088585253\n",
            "MeanSlowdown: \t 5.250541196492901\n",
            "MeanLen: \t 152.78 +- 16.446628833897847\n",
            "MeanEntropy \t 0.39278872571271256\n",
            "Elapsed time\t 10.683558940887451 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 944\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15311\n",
            "MaxRew: \t -184.2738228438228\n",
            "MeanRew: \t -185.38976989676982 +- 78.03713388566335\n",
            "MeanSlowdown: \t 5.227872496821361\n",
            "MeanLen: \t 153.11 +- 17.086190330205266\n",
            "MeanEntropy \t 0.39027738990800503\n",
            "Elapsed time\t 10.575234651565552 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 945\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15336\n",
            "MaxRew: \t -184.323658008658\n",
            "MeanRew: \t -185.22127089577086 +- 77.94584778383452\n",
            "MeanSlowdown: \t 5.224262541435837\n",
            "MeanLen: \t 153.36 +- 17.09065241586757\n",
            "MeanEntropy \t 0.3966133606800787\n",
            "Elapsed time\t 10.84001088142395 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 946\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15331\n",
            "MaxRew: \t -183.98922577422573\n",
            "MeanRew: \t -186.79421678321677 +- 79.16278938627018\n",
            "MeanSlowdown: \t 5.2689269821088\n",
            "MeanLen: \t 153.31 +- 17.538925280643625\n",
            "MeanEntropy \t 0.39086886559780676\n",
            "Elapsed time\t 10.487735509872437 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 947\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15486\n",
            "MaxRew: \t -184.15562271062268\n",
            "MeanRew: \t -186.6293782883782 +- 77.69749956698595\n",
            "MeanSlowdown: \t 5.250822213094422\n",
            "MeanLen: \t 154.86 +- 19.69163274083691\n",
            "MeanEntropy \t 0.3874993321675385\n",
            "Elapsed time\t 11.294074773788452 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 948\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15510\n",
            "MaxRew: \t -184.53794372294368\n",
            "MeanRew: \t -187.0800081585081 +- 77.6766950941395\n",
            "MeanSlowdown: \t 5.267166484444641\n",
            "MeanLen: \t 155.1 +- 19.366207682455542\n",
            "MeanEntropy \t 0.3964868515799072\n",
            "Elapsed time\t 10.686161041259766 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 949\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15439\n",
            "MaxRew: \t -184.33135031635027\n",
            "MeanRew: \t -189.4907012987012 +- 79.58043818611543\n",
            "MeanSlowdown: \t 5.333844706389541\n",
            "MeanLen: \t 154.39 +- 19.000471046792498\n",
            "MeanEntropy \t 0.4025807301294486\n",
            "Elapsed time\t 10.760223150253296 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 950\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15285\n",
            "MaxRew: \t -184.25241924741923\n",
            "MeanRew: \t -185.6023894438894 +- 77.51716364181286\n",
            "MeanSlowdown: \t 5.2351180117231255\n",
            "MeanLen: \t 152.85 +- 16.340976103036194\n",
            "MeanEntropy \t 0.4134363153091538\n",
            "Elapsed time\t 10.430904388427734 seconds\n",
            "-----------------\n",
            "Load on # 0 resource dimension is 1.167\n",
            "Load on # 1 resource dimension is 1.2995999999999999\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -237.19452214452218\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -455.2932400932398\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -261.095571095571\n",
            "---------- Random -----------\n",
            "total discount reward : \t -238.1874125874126\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.59848484848484\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -190.28030303030306\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -315.9681318681318\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -403.19340659340645\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -183.14405594405588\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -202.31037296037283\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -178.79157509157517\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -289.27399267399267\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -108.59413919413916\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -162.4190476190477\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -149.7764402264401\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -280.3205794205793\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -269.1272394272395\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -394.3753912753912\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -123.45536130536138\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -151.3015151515152\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -244.59220779220786\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -287.85281385281365\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 951\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15349\n",
            "MaxRew: \t -184.40158841158836\n",
            "MeanRew: \t -186.15996836496836 +- 77.45020870738256\n",
            "MeanSlowdown: \t 5.2503172963400235\n",
            "MeanLen: \t 153.49 +- 16.996173098671356\n",
            "MeanEntropy \t 0.41341798684055586\n",
            "Elapsed time\t 36.099308013916016 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 952\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15288\n",
            "MaxRew: \t -184.65461038961035\n",
            "MeanRew: \t -185.5905787545787 +- 77.65363425303303\n",
            "MeanSlowdown: \t 5.233810015741835\n",
            "MeanLen: \t 152.88 +- 16.89809456713981\n",
            "MeanEntropy \t 0.4109591729481782\n",
            "Elapsed time\t 10.76912260055542 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 953\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15288\n",
            "MaxRew: \t -184.66944555444553\n",
            "MeanRew: \t -185.1373704628704 +- 77.89601161849754\n",
            "MeanSlowdown: \t 5.220814587874247\n",
            "MeanLen: \t 152.88 +- 16.723803395161045\n",
            "MeanEntropy \t 0.40684529427436533\n",
            "Elapsed time\t 10.497232675552368 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 954\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15336\n",
            "MaxRew: \t -184.66944555444553\n",
            "MeanRew: \t -185.31765601065604 +- 77.82997121214989\n",
            "MeanSlowdown: \t 5.225742638043774\n",
            "MeanLen: \t 153.36 +- 16.433818789313698\n",
            "MeanEntropy \t 0.4113014829889995\n",
            "Elapsed time\t 10.83261489868164 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 955\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15323\n",
            "MaxRew: \t -184.5801598401598\n",
            "MeanRew: \t -185.44456160506152 +- 78.1423881256981\n",
            "MeanSlowdown: \t 5.2263041440272815\n",
            "MeanLen: \t 153.23 +- 17.573192652446508\n",
            "MeanEntropy \t 0.40752940907713026\n",
            "Elapsed time\t 10.951850652694702 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 956\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15254\n",
            "MaxRew: \t -184.5801598401598\n",
            "MeanRew: \t -185.56060306360297 +- 77.56111401251466\n",
            "MeanSlowdown: \t 5.233023330835831\n",
            "MeanLen: \t 152.54 +- 16.809770968100665\n",
            "MeanEntropy \t 0.40736901812321313\n",
            "Elapsed time\t 10.513682126998901 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 957\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15340\n",
            "MaxRew: \t -184.70406093906087\n",
            "MeanRew: \t -185.2129783549783 +- 77.97389060608228\n",
            "MeanSlowdown: \t 5.2234587760724125\n",
            "MeanLen: \t 153.4 +- 17.52426888631877\n",
            "MeanEntropy \t 0.4188101276170334\n",
            "Elapsed time\t 10.826297998428345 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 958\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15323\n",
            "MaxRew: \t -184.10360972360965\n",
            "MeanRew: \t -185.15428138528128 +- 77.78364270061755\n",
            "MeanSlowdown: \t 5.222099604940514\n",
            "MeanLen: \t 153.23 +- 16.860518971846624\n",
            "MeanEntropy \t 0.4152701633588921\n",
            "Elapsed time\t 10.623342752456665 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 959\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15296\n",
            "MaxRew: \t -184.10360972360968\n",
            "MeanRew: \t -184.99489776889772 +- 77.95543372632896\n",
            "MeanSlowdown: \t 5.218139843111435\n",
            "MeanLen: \t 152.96 +- 16.813637322126347\n",
            "MeanEntropy \t 0.41450828498295705\n",
            "Elapsed time\t 10.691125392913818 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 960\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15238\n",
            "MaxRew: \t -184.0264618714618\n",
            "MeanRew: \t -185.46771062271057 +- 77.54320586178223\n",
            "MeanSlowdown: \t 5.231408127856992\n",
            "MeanLen: \t 152.38 +- 16.76292337272947\n",
            "MeanEntropy \t 0.4119645991093632\n",
            "Elapsed time\t 10.479014158248901 seconds\n",
            "-----------------\n",
            "Load on # 0 resource dimension is 1.167\n",
            "Load on # 1 resource dimension is 1.2995999999999999\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -233.78193473193477\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -455.2932400932398\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -261.095571095571\n",
            "---------- Random -----------\n",
            "total discount reward : \t -238.1874125874126\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.59848484848484\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -190.28030303030306\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -315.9681318681318\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -403.19340659340645\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -183.14405594405588\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -202.31037296037283\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -178.79157509157517\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -289.27399267399267\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -100.07985347985343\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -189.8826007326008\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -150.85812520812505\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -294.0295537795539\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -328.91831501831496\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -330.12281052281054\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -123.45536130536138\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -151.3015151515152\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -348.0268398268394\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -343.45281385281345\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 961\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15349\n",
            "MaxRew: \t -184.62365800865797\n",
            "MeanRew: \t -185.1920837495837 +- 78.0152223128786\n",
            "MeanSlowdown: \t 5.223411507999576\n",
            "MeanLen: \t 153.49 +- 17.507995316426147\n",
            "MeanEntropy \t 0.4164003341221056\n",
            "Elapsed time\t 34.48527908325195 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 962\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15310\n",
            "MaxRew: \t -184.65827339327336\n",
            "MeanRew: \t -185.0143694638694 +- 77.97631892004787\n",
            "MeanSlowdown: \t 5.21812086114643\n",
            "MeanLen: \t 153.1 +- 17.002058698875263\n",
            "MeanEntropy \t 0.4162411310766255\n",
            "Elapsed time\t 19.2869131565094 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 963\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15277\n",
            "MaxRew: \t -184.62365800865797\n",
            "MeanRew: \t -184.92822261072251 +- 78.06354387917531\n",
            "MeanSlowdown: \t 5.215957598272939\n",
            "MeanLen: \t 152.77 +- 17.147510023324088\n",
            "MeanEntropy \t 0.4159938901244349\n",
            "Elapsed time\t 10.553435325622559 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 964\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15294\n",
            "MaxRew: \t -184.62365800865797\n",
            "MeanRew: \t -185.13184465534462 +- 78.13914927650828\n",
            "MeanSlowdown: \t 5.22129829923864\n",
            "MeanLen: \t 152.94 +- 16.89841412677533\n",
            "MeanEntropy \t 0.41831622990871253\n",
            "Elapsed time\t 10.752519130706787 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 965\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15319\n",
            "MaxRew: \t -184.2892257742257\n",
            "MeanRew: \t -185.17135231435225 +- 78.23286521849737\n",
            "MeanSlowdown: \t 5.223083554702873\n",
            "MeanLen: \t 153.19 +- 17.261341199339057\n",
            "MeanEntropy \t 0.41236471039246614\n",
            "Elapsed time\t 10.849519729614258 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 966\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15230\n",
            "MaxRew: \t -183.7221994671994\n",
            "MeanRew: \t -184.97423576423574 +- 77.8221315629532\n",
            "MeanSlowdown: \t 5.217316111918384\n",
            "MeanLen: \t 152.3 +- 17.138553031105047\n",
            "MeanEntropy \t 0.4062660253672164\n",
            "Elapsed time\t 10.5099036693573 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 967\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15343\n",
            "MaxRew: \t -184.13922577422574\n",
            "MeanRew: \t -185.83318714618713 +- 77.56662178181605\n",
            "MeanSlowdown: \t 5.239702684088699\n",
            "MeanLen: \t 153.43 +- 17.620587390890236\n",
            "MeanEntropy \t 0.4178568464022013\n",
            "Elapsed time\t 10.838112831115723 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 968\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15303\n",
            "MaxRew: \t -184.13922577422574\n",
            "MeanRew: \t -186.28471561771562 +- 78.36700079960254\n",
            "MeanSlowdown: \t 5.254913703720521\n",
            "MeanLen: \t 153.03 +- 16.872732440242157\n",
            "MeanEntropy \t 0.42674471426084376\n",
            "Elapsed time\t 10.864490747451782 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 969\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15354\n",
            "MaxRew: \t -183.2169896769896\n",
            "MeanRew: \t -185.4293328338328 +- 78.30619365004739\n",
            "MeanSlowdown: \t 5.22117253180447\n",
            "MeanLen: \t 153.54 +- 17.798550502779715\n",
            "MeanEntropy \t 0.41781087008485274\n",
            "Elapsed time\t 10.778531312942505 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 970\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15351\n",
            "MaxRew: \t -182.85280219780216\n",
            "MeanRew: \t -185.18118031968027 +- 77.78875893632856\n",
            "MeanSlowdown: \t 5.2182922233675715\n",
            "MeanLen: \t 153.51 +- 16.486051680132512\n",
            "MeanEntropy \t 0.4150925197471571\n",
            "Elapsed time\t 10.695960760116577 seconds\n",
            "-----------------\n",
            "Load on # 0 resource dimension is 1.167\n",
            "Load on # 1 resource dimension is 1.2995999999999999\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -253.0506993006994\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -455.2932400932398\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -261.095571095571\n",
            "---------- Random -----------\n",
            "total discount reward : \t -255.58473193473196\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.59848484848484\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -190.28030303030306\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -302.4571428571428\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -383.76227106227105\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -172.52610722610723\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -213.14242424242417\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -214.62637362637378\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -282.02673992673994\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -90.33278388278384\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -143.7804029304029\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -151.85812520812505\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -358.01346986346965\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -249.68295038295042\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -437.0484182484183\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -99.99965034965041\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -186.26736596736606\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -190.24502164502164\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -262.977489177489\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 971\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15336\n",
            "MaxRew: \t -182.35370629370624\n",
            "MeanRew: \t -186.19541774891775 +- 77.18531827769056\n",
            "MeanSlowdown: \t 5.253441742916175\n",
            "MeanLen: \t 153.36 +- 17.67456930168314\n",
            "MeanEntropy \t 0.41876904198712034\n",
            "Elapsed time\t 40.00044012069702 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 972\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15367\n",
            "MaxRew: \t -183.1284082584082\n",
            "MeanRew: \t -184.68329087579082 +- 77.6541322677813\n",
            "MeanSlowdown: \t 5.207259719624701\n",
            "MeanLen: \t 153.67 +- 17.55964407384159\n",
            "MeanEntropy \t 0.40869284790102095\n",
            "Elapsed time\t 10.752297639846802 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 973\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15364\n",
            "MaxRew: \t -184.1647452547452\n",
            "MeanRew: \t -184.77994821844814 +- 77.94646563115401\n",
            "MeanSlowdown: \t 5.213792003451094\n",
            "MeanLen: \t 153.64 +- 17.064887928140635\n",
            "MeanEntropy \t 0.401338150389963\n",
            "Elapsed time\t 10.882921695709229 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 974\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15349\n",
            "MaxRew: \t -184.00806027306024\n",
            "MeanRew: \t -184.8598924408924 +- 77.90797368108612\n",
            "MeanSlowdown: \t 5.216134168861441\n",
            "MeanLen: \t 153.49 +- 17.13855011370565\n",
            "MeanEntropy \t 0.3994889087482837\n",
            "Elapsed time\t 11.210597515106201 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 975\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15350\n",
            "MaxRew: \t -183.9931335331335\n",
            "MeanRew: \t -185.32790842490834 +- 78.7855384964423\n",
            "MeanSlowdown: \t 5.229032227242454\n",
            "MeanLen: \t 153.5 +- 17.361739544181624\n",
            "MeanEntropy \t 0.39638862037254496\n",
            "Elapsed time\t 10.666075706481934 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 976\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15280\n",
            "MaxRew: \t -183.9825108225108\n",
            "MeanRew: \t -184.68856310356304 +- 77.87037635015602\n",
            "MeanSlowdown: \t 5.210597522742409\n",
            "MeanLen: \t 152.8 +- 16.792855623746668\n",
            "MeanEntropy \t 0.40129525357339463\n",
            "Elapsed time\t 10.669509649276733 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 977\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15239\n",
            "MaxRew: \t -183.7491774891774\n",
            "MeanRew: \t -184.57863153513154 +- 77.82526518923707\n",
            "MeanSlowdown: \t 5.207808058418854\n",
            "MeanLen: \t 152.39 +- 16.81124326157944\n",
            "MeanEntropy \t 0.4026892501822066\n",
            "Elapsed time\t 10.432831525802612 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 978\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15305\n",
            "MaxRew: \t -183.75434232434228\n",
            "MeanRew: \t -187.19250849150842 +- 78.80961143702352\n",
            "MeanSlowdown: \t 5.279564855907567\n",
            "MeanLen: \t 153.05 +- 18.01409170621711\n",
            "MeanEntropy \t 0.39355692523313635\n",
            "Elapsed time\t 11.656789064407349 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 979\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15410\n",
            "MaxRew: \t -183.30549950049948\n",
            "MeanRew: \t -186.02293822843814 +- 77.3605859078585\n",
            "MeanSlowdown: \t 5.246660254588643\n",
            "MeanLen: \t 154.1 +- 17.060773722196775\n",
            "MeanEntropy \t 0.40113080651171984\n",
            "Elapsed time\t 10.697346448898315 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 980\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15362\n",
            "MaxRew: \t -183.78520313020312\n",
            "MeanRew: \t -185.6658709623709 +- 77.47461268748295\n",
            "MeanSlowdown: \t 5.237533352064602\n",
            "MeanLen: \t 153.62 +- 16.680995174149533\n",
            "MeanEntropy \t 0.40107593494103805\n",
            "Elapsed time\t 10.76076054573059 seconds\n",
            "-----------------\n",
            "Load on # 0 resource dimension is 1.167\n",
            "Load on # 1 resource dimension is 1.2995999999999999\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -255.50874125874137\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -455.2932400932398\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -261.095571095571\n",
            "---------- Random -----------\n",
            "total discount reward : \t -250.92773892773894\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.59848484848484\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -170.68939393939394\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -309.9681318681319\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -366.1139194139193\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -187.05944055944053\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -221.54510489510483\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -175.1956043956045\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -350.0820512820514\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -104.2965201465201\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -223.40879120879129\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -150.16691641691628\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -278.9352813852814\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -264.0338661338661\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -337.43616383616376\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -122.05664335664343\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -156.1559440559441\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -181.07229437229432\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -402.88441558441525\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 981\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15389\n",
            "MaxRew: \t -184.12407425907423\n",
            "MeanRew: \t -185.05908308358303 +- 77.87142825991351\n",
            "MeanSlowdown: \t 5.219201740494354\n",
            "MeanLen: \t 153.89 +- 16.924476358221543\n",
            "MeanEntropy \t 0.39074612603915765\n",
            "Elapsed time\t 33.33574414253235 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 982\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15298\n",
            "MaxRew: \t -184.062957042957\n",
            "MeanRew: \t -185.0854502164502 +- 77.98244716748435\n",
            "MeanSlowdown: \t 5.219929284730421\n",
            "MeanLen: \t 152.98 +- 16.77914181357318\n",
            "MeanEntropy \t 0.3914492781074238\n",
            "Elapsed time\t 10.690495014190674 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 983\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15307\n",
            "MaxRew: \t -183.7252214452214\n",
            "MeanRew: \t -184.90177605727595 +- 78.02181419874543\n",
            "MeanSlowdown: \t 5.212826386234572\n",
            "MeanLen: \t 153.07 +- 17.327582058671663\n",
            "MeanEntropy \t 0.38751134353650446\n",
            "Elapsed time\t 10.842597007751465 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 984\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15293\n",
            "MaxRew: \t -184.22384115884114\n",
            "MeanRew: \t -184.88144022644022 +- 78.09134648296038\n",
            "MeanSlowdown: \t 5.214322609208972\n",
            "MeanLen: \t 152.93 +- 16.903996568859096\n",
            "MeanEntropy \t 0.38834529295989195\n",
            "Elapsed time\t 10.66378664970398 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 985\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15296\n",
            "MaxRew: \t -183.7586896436896\n",
            "MeanRew: \t -185.20914935064928 +- 77.69399526465098\n",
            "MeanSlowdown: \t 5.221788067951751\n",
            "MeanLen: \t 152.96 +- 16.42736740929599\n",
            "MeanEntropy \t 0.3840667916071517\n",
            "Elapsed time\t 10.742107391357422 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 986\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15324\n",
            "MaxRew: \t -184.5331818181818\n",
            "MeanRew: \t -185.02487695637686 +- 78.05681861409137\n",
            "MeanSlowdown: \t 5.218277324001756\n",
            "MeanLen: \t 153.24 +- 17.26100808180102\n",
            "MeanEntropy \t 0.3933395957886931\n",
            "Elapsed time\t 10.772826910018921 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 987\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15247\n",
            "MaxRew: \t -184.3558924408924\n",
            "MeanRew: \t -185.15717898767898 +- 77.73666262691978\n",
            "MeanSlowdown: \t 5.222130601406169\n",
            "MeanLen: \t 152.47 +- 17.21537394307774\n",
            "MeanEntropy \t 0.38388185150518006\n",
            "Elapsed time\t 11.092345476150513 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 988\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15358\n",
            "MaxRew: \t -184.25254578754576\n",
            "MeanRew: \t -185.0596253746253 +- 78.09451751404282\n",
            "MeanSlowdown: \t 5.212945956205342\n",
            "MeanLen: \t 153.58 +- 17.765235714732295\n",
            "MeanEntropy \t 0.39208710420223797\n",
            "Elapsed time\t 10.958861112594604 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 989\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15304\n",
            "MaxRew: \t -184.0997885447885\n",
            "MeanRew: \t -184.94343639693633 +- 78.24192568013063\n",
            "MeanSlowdown: \t 5.212272609899102\n",
            "MeanLen: \t 153.04 +- 16.979352166675852\n",
            "MeanEntropy \t 0.3903668150108834\n",
            "Elapsed time\t 10.788464784622192 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 990\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15245\n",
            "MaxRew: \t -183.6210173160173\n",
            "MeanRew: \t -184.75414985014982 +- 78.06884094938664\n",
            "MeanSlowdown: \t 5.210538864544547\n",
            "MeanLen: \t 152.45 +- 16.921805459229226\n",
            "MeanEntropy \t 0.3961551435354435\n",
            "Elapsed time\t 10.417595863342285 seconds\n",
            "-----------------\n",
            "Load on # 0 resource dimension is 1.167\n",
            "Load on # 1 resource dimension is 1.2995999999999999\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -225.00547785547792\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -455.2932400932398\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -261.095571095571\n",
            "---------- Random -----------\n",
            "total discount reward : \t -238.1874125874126\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -77.59848484848484\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -118.92424242424241\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -86.42424242424241\n",
            "---------- Random -----------\n",
            "total discount reward : \t -190.28030303030306\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -305.3747252747252\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -583.492673992674\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -433.3758241758238\n",
            "---------- Random -----------\n",
            "total discount reward : \t -441.62344322344296\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -188.92610722610718\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -311.6418414918413\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -197.70058275058275\n",
            "---------- Random -----------\n",
            "total discount reward : \t -240.04382284382285\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -211.30256410256425\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -487.2333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -273.20769230769235\n",
            "---------- Random -----------\n",
            "total discount reward : \t -234.4765567765567\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -115.32582417582414\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -159.10842490842504\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -98.98241758241753\n",
            "---------- Random -----------\n",
            "total discount reward : \t -201.54358974358985\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -149.16691641691628\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -602.6029637029635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -429.4745254745253\n",
            "---------- Random -----------\n",
            "total discount reward : \t -269.6554445554445\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -296.05397935397957\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -620.1728604728605\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -469.40126540126556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -330.550715950716\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -125.43088578088586\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -205.19020979020993\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -148.6342657342658\n",
            "---------- Random -----------\n",
            "total discount reward : \t -180.54673659673665\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -182.37099567099565\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -546.7073593073595\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -254.8952380952381\n",
            "---------- Random -----------\n",
            "total discount reward : \t -336.2437229437227\n",
            "/content/drive/colab/slow_down_cdf.py:161: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure()\n",
            "/content/drive/colab/pg_re.py:160: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(12, 5))\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 991\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15269\n",
            "MaxRew: \t -183.21162670662665\n",
            "MeanRew: \t -184.64869896769898 +- 78.011881663909\n",
            "MeanSlowdown: \t 5.206321319109043\n",
            "MeanLen: \t 152.69 +- 16.69173148597832\n",
            "MeanEntropy \t 0.38657077762600595\n",
            "Elapsed time\t 37.14685010910034 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 992\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15246\n",
            "MaxRew: \t -184.01432400932396\n",
            "MeanRew: \t -186.11082051282042 +- 76.72500338082685\n",
            "MeanSlowdown: \t 5.250466049102413\n",
            "MeanLen: \t 152.46 +- 16.52780687205656\n",
            "MeanEntropy \t 0.3887884357119185\n",
            "Elapsed time\t 10.425192832946777 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 993\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15269\n",
            "MaxRew: \t -183.81185148185142\n",
            "MeanRew: \t -184.80208291708286 +- 77.65524631206921\n",
            "MeanSlowdown: \t 5.211435291997952\n",
            "MeanLen: \t 152.69 +- 17.276397193859605\n",
            "MeanEntropy \t 0.38941565768653724\n",
            "Elapsed time\t 10.929240942001343 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 994\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15216\n",
            "MaxRew: \t -183.43163170163166\n",
            "MeanRew: \t -185.2742031302031 +- 77.11660863245064\n",
            "MeanSlowdown: \t 5.227189827218237\n",
            "MeanLen: \t 152.16 +- 16.384578114800515\n",
            "MeanEntropy \t 0.3907101612825215\n",
            "Elapsed time\t 10.641486167907715 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 995\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15453\n",
            "MaxRew: \t -183.38584415584413\n",
            "MeanRew: \t -186.63041192141193 +- 78.28478498436598\n",
            "MeanSlowdown: \t 5.263262741616921\n",
            "MeanLen: \t 154.53 +- 16.171861364728553\n",
            "MeanEntropy \t 0.40947413909616787\n",
            "Elapsed time\t 10.925881624221802 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 996\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15966\n",
            "MaxRew: \t -183.29633866133864\n",
            "MeanRew: \t -195.75140675990679 +- 82.73341975575315\n",
            "MeanSlowdown: \t 5.468011327711756\n",
            "MeanLen: \t 159.66 +- 22.035072044356927\n",
            "MeanEntropy \t 0.391612864863451\n",
            "Elapsed time\t 11.136372327804565 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 997\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15594\n",
            "MaxRew: \t -183.8622594072594\n",
            "MeanRew: \t -189.39583383283377 +- 81.43843393416492\n",
            "MeanSlowdown: \t 5.335547217287833\n",
            "MeanLen: \t 155.94 +- 18.45579583762239\n",
            "MeanEntropy \t 0.41653749327267164\n",
            "Elapsed time\t 10.727564334869385 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 998\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15649\n",
            "MaxRew: \t -184.2629287379287\n",
            "MeanRew: \t -186.34949100899098 +- 78.80905449104146\n",
            "MeanSlowdown: \t 5.244750339327624\n",
            "MeanLen: \t 156.49 +- 19.74360402763386\n",
            "MeanEntropy \t 0.38447040557986123\n",
            "Elapsed time\t 11.28661298751831 seconds\n",
            "-----------------\n",
            "9 out of 10\n",
            "-----------------\n",
            "Iteration: \t 999\n",
            "NumTrajs: \t 100\n",
            "NumTimesteps: \t 15443\n",
            "MaxRew: \t -183.30045454545453\n",
            "MeanRew: \t -185.16543190143184 +- 78.19320187297235\n",
            "MeanSlowdown: \t 5.222554453122635\n",
            "MeanLen: \t 154.43 +- 17.261665620675195\n",
            "MeanEntropy \t 0.3861851130812872\n",
            "Elapsed time\t 10.650312185287476 seconds\n",
            "-----------------\n",
            "time cost 14267.739994764328 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIkcKOg3XbAO"
      },
      "source": [
        "Next step is to launch testing and comparing experiemnt on unseen examples with pg agent just trained\n",
        "\n",
        "\n",
        "\n",
        "> --unseen - use new data to test algorithm\n",
        "\n",
        "\n",
        "```\n",
        "!python launcher.py --exp_type=test --simu_len=50 --num_ex=10 --pg_re=data/pg_re_1600.pkl --unseen=True\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETbuw957CIfE",
        "outputId": "12c2f262-3ae0-4ea9-9221-ad53d5a5f79c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python launcher.py --exp_type=test --simu_len=50 --num_ex=100 --pg_re=data/pg_re_40.pkl --unseen=True"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load on # 0 resource dimension is 1.28434\n",
            "Load on # 1 resource dimension is 1.31332\n",
            "\n",
            "\n",
            "\n",
            "=============== 0 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -149.90795870795873\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -222.10795870795872\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -113.40795870795868\n",
            "---------- Random -----------\n",
            "total discount reward : \t -219.989776889777\n",
            "\n",
            "\n",
            "\n",
            "=============== 1 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -180.0437062937064\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -266.06550116550125\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -202.97703962703974\n",
            "---------- Random -----------\n",
            "total discount reward : \t -243.01550116550115\n",
            "\n",
            "\n",
            "\n",
            "=============== 2 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -209.72812187812195\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -301.82241092241065\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -212.57695637695645\n",
            "---------- Random -----------\n",
            "total discount reward : \t -250.70889110889107\n",
            "\n",
            "\n",
            "\n",
            "=============== 3 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -158.7571428571429\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -224.09264069264069\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -153.7116883116884\n",
            "---------- Random -----------\n",
            "total discount reward : \t -180.91168831168844\n",
            "\n",
            "\n",
            "\n",
            "=============== 4 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -94.27051282051274\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -174.18717948717955\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -106.70384615384611\n",
            "---------- Random -----------\n",
            "total discount reward : \t -154.43717948717946\n",
            "\n",
            "\n",
            "\n",
            "=============== 5 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -168.10139860139859\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -232.0256410256411\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -213.35897435897442\n",
            "---------- Random -----------\n",
            "total discount reward : \t -204.25139860139856\n",
            "\n",
            "\n",
            "\n",
            "=============== 6 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -145.8212121212121\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -253.3878787878788\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -180.9712121212121\n",
            "---------- Random -----------\n",
            "total discount reward : \t -190.3893939393939\n",
            "\n",
            "\n",
            "\n",
            "=============== 7 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -132.83003663003672\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -216.16826506826507\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -95.71748251748248\n",
            "---------- Random -----------\n",
            "total discount reward : \t -143.30233100233107\n",
            "\n",
            "\n",
            "\n",
            "=============== 8 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -169.14275724275723\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -239.41851481851486\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -106.55487845487842\n",
            "---------- Random -----------\n",
            "total discount reward : \t -252.26699966699968\n",
            "\n",
            "\n",
            "\n",
            "=============== 9 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -178.39490509490506\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -334.7288211788211\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -232.71010656010648\n",
            "---------- Random -----------\n",
            "total discount reward : \t -258.2716450216449\n",
            "\n",
            "\n",
            "\n",
            "=============== 10 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -327.71048951048977\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -381.8510489510491\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -128.1771561771561\n",
            "---------- Random -----------\n",
            "total discount reward : \t -268.1468531468533\n",
            "\n",
            "\n",
            "\n",
            "=============== 11 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -181.4139194139195\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -222.78058608058606\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -142.41391941391947\n",
            "---------- Random -----------\n",
            "total discount reward : \t -208.93956043956055\n",
            "\n",
            "\n",
            "\n",
            "=============== 12 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -85.94047619047616\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -89.68809523809519\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -80.54696969696967\n",
            "---------- Random -----------\n",
            "total discount reward : \t -142.34696969696975\n",
            "\n",
            "\n",
            "\n",
            "=============== 13 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -348.6489510489509\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -337.4305527805526\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -347.14072594072576\n",
            "---------- Random -----------\n",
            "total discount reward : \t -293.50804195804193\n",
            "\n",
            "\n",
            "\n",
            "=============== 14 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -138.7509657009658\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -161.07239427239435\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -97.23906093906092\n",
            "---------- Random -----------\n",
            "total discount reward : \t -152.33429903429908\n",
            "\n",
            "\n",
            "\n",
            "=============== 15 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -148.47902097902107\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -184.84568764568783\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -77.67902097902093\n",
            "---------- Random -----------\n",
            "total discount reward : \t -162.0123543123544\n",
            "\n",
            "\n",
            "\n",
            "=============== 16 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -172.61018981018975\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -188.9206793206793\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -135.26916416916416\n",
            "---------- Random -----------\n",
            "total discount reward : \t -151.87942057942055\n",
            "\n",
            "\n",
            "\n",
            "=============== 17 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -182.61188811188813\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -225.83613053613033\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -136.8209790209789\n",
            "---------- Random -----------\n",
            "total discount reward : \t -220.6997668997667\n",
            "\n",
            "\n",
            "\n",
            "=============== 18 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -166.4738095238095\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -267.02142857142854\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -181.32619047619048\n",
            "---------- Random -----------\n",
            "total discount reward : \t -217.5023809523809\n",
            "\n",
            "\n",
            "\n",
            "=============== 19 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -251.44848484848472\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -283.58528138528135\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -154.26969696969698\n",
            "---------- Random -----------\n",
            "total discount reward : \t -289.7519480519481\n",
            "\n",
            "\n",
            "\n",
            "=============== 20 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -211.72953712953716\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -242.0676323676322\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -134.3201465201465\n",
            "---------- Random -----------\n",
            "total discount reward : \t -204.97422577422577\n",
            "\n",
            "\n",
            "\n",
            "=============== 21 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -242.26190476190465\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -323.85238095238105\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -198.7523809523808\n",
            "---------- Random -----------\n",
            "total discount reward : \t -295.92380952380955\n",
            "\n",
            "\n",
            "\n",
            "=============== 22 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -120.82762237762238\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -217.24020979020972\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -112.25069930069934\n",
            "---------- Random -----------\n",
            "total discount reward : \t -195.81596736596734\n",
            "\n",
            "\n",
            "\n",
            "=============== 23 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -203.7057109557109\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -287.3193473193474\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -271.54020979020993\n",
            "---------- Random -----------\n",
            "total discount reward : \t -228.03904428904434\n",
            "\n",
            "\n",
            "\n",
            "=============== 24 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -307.8396270396269\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -379.93578088578073\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -263.8629370629371\n",
            "---------- Random -----------\n",
            "total discount reward : \t -283.9165501165501\n",
            "\n",
            "\n",
            "\n",
            "=============== 25 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -147.53095238095236\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -220.7642857142857\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -243.76428571428562\n",
            "---------- Random -----------\n",
            "total discount reward : \t -200.8809523809524\n",
            "\n",
            "\n",
            "\n",
            "=============== 26 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -260.89627039627044\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -372.4796037296036\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -174.9962703962705\n",
            "---------- Random -----------\n",
            "total discount reward : \t -270.2796037296037\n",
            "\n",
            "\n",
            "\n",
            "=============== 27 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -201.71471861471858\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -263.47489177489166\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -222.0506493506493\n",
            "---------- Random -----------\n",
            "total discount reward : \t -204.9844155844155\n",
            "\n",
            "\n",
            "\n",
            "=============== 28 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -81.05454545454542\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -73.78787878787877\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -63.92121212121215\n",
            "---------- Random -----------\n",
            "total discount reward : \t -114.62121212121208\n",
            "\n",
            "\n",
            "\n",
            "=============== 29 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -212.5\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -214.22435897435898\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -173.24358974358975\n",
            "---------- Random -----------\n",
            "total discount reward : \t -267.2371794871794\n",
            "\n",
            "\n",
            "\n",
            "=============== 30 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -145.4432900432901\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -145.74212454212454\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -108.60952380952382\n",
            "---------- Random -----------\n",
            "total discount reward : \t -172.51904761904754\n",
            "\n",
            "\n",
            "\n",
            "=============== 31 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -118.98809523809516\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -131.41666666666663\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -101.41666666666661\n",
            "---------- Random -----------\n",
            "total discount reward : \t -169.17857142857144\n",
            "\n",
            "\n",
            "\n",
            "=============== 32 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -198.9307692307692\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -354.9692307692307\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -135.30256410256402\n",
            "---------- Random -----------\n",
            "total discount reward : \t -254.12307692307692\n",
            "\n",
            "\n",
            "\n",
            "=============== 33 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -198.442191142191\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -233.20909090909083\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -176.8757575757575\n",
            "---------- Random -----------\n",
            "total discount reward : \t -252.18344988344973\n",
            "\n",
            "\n",
            "\n",
            "=============== 34 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -121.30567765567758\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -125.27619047619045\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -103.37619047619043\n",
            "---------- Random -----------\n",
            "total discount reward : \t -145.5428571428572\n",
            "\n",
            "\n",
            "\n",
            "=============== 35 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -200.36403596403593\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -219.40451215451222\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -135.34498834498837\n",
            "---------- Random -----------\n",
            "total discount reward : \t -202.53546453546457\n",
            "\n",
            "\n",
            "\n",
            "=============== 36 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -170.01515151515153\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -233.10303030303018\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -202.1363636363635\n",
            "---------- Random -----------\n",
            "total discount reward : \t -237.71818181818176\n",
            "\n",
            "\n",
            "\n",
            "=============== 37 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -142.9833333333333\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -211.48333333333323\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -207.48333333333318\n",
            "---------- Random -----------\n",
            "total discount reward : \t -189.4\n",
            "\n",
            "\n",
            "\n",
            "=============== 38 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -146.8572927072926\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -181.83772893772888\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -219.65166500166498\n",
            "---------- Random -----------\n",
            "total discount reward : \t -175.27071262071257\n",
            "\n",
            "\n",
            "\n",
            "=============== 39 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -229.92905427905436\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -262.0861971361971\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -183.0123876123877\n",
            "---------- Random -----------\n",
            "total discount reward : \t -181.3381451881453\n",
            "\n",
            "\n",
            "\n",
            "=============== 40 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -171.11981351981353\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -211.42237762237758\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -183.38904428904434\n",
            "---------- Random -----------\n",
            "total discount reward : \t -191.50955710955708\n",
            "\n",
            "\n",
            "\n",
            "=============== 41 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -96.38589743589746\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -170.20256410256408\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -116.0410256410256\n",
            "---------- Random -----------\n",
            "total discount reward : \t -141.76923076923075\n",
            "\n",
            "\n",
            "\n",
            "=============== 42 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -153.81340326340327\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -216.4518648018648\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -125.41340326340325\n",
            "---------- Random -----------\n",
            "total discount reward : \t -194.01340326340326\n",
            "\n",
            "\n",
            "\n",
            "=============== 43 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -269.8190476190476\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -365.9138528138529\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -233.89047619047636\n",
            "---------- Random -----------\n",
            "total discount reward : \t -318.3199134199134\n",
            "\n",
            "\n",
            "\n",
            "=============== 44 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -92.39358974358973\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -117.62086247086246\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -91.75722610722607\n",
            "---------- Random -----------\n",
            "total discount reward : \t -136.56501831501828\n",
            "\n",
            "\n",
            "\n",
            "=============== 45 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -309.13896103896104\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -317.70238095238096\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -167.2071428571429\n",
            "---------- Random -----------\n",
            "total discount reward : \t -264.3500000000001\n",
            "\n",
            "\n",
            "\n",
            "=============== 46 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -268.7073593073591\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -380.0740259740259\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -187.4406926406925\n",
            "---------- Random -----------\n",
            "total discount reward : \t -224.60735930735922\n",
            "\n",
            "\n",
            "\n",
            "=============== 47 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -129.97948717948722\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -214.12234432234436\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -111.64615384615382\n",
            "---------- Random -----------\n",
            "total discount reward : \t -118.24615384615387\n",
            "\n",
            "\n",
            "\n",
            "=============== 48 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -227.15018315018324\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -263.89878454878453\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -133.01929736929745\n",
            "---------- Random -----------\n",
            "total discount reward : \t -232.78211788211786\n",
            "\n",
            "\n",
            "\n",
            "=============== 49 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -241.55567765567764\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -266.0736263736265\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -181.53003663003662\n",
            "---------- Random -----------\n",
            "total discount reward : \t -237.63260073260076\n",
            "\n",
            "\n",
            "\n",
            "=============== 50 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -144.51904761904763\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -167.50000000000003\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -117.56666666666663\n",
            "---------- Random -----------\n",
            "total discount reward : \t -205.37619047619054\n",
            "\n",
            "\n",
            "\n",
            "=============== 51 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -410.175974025974\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -365.31883116883137\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -164.40541125541117\n",
            "---------- Random -----------\n",
            "total discount reward : \t -269.6521645021648\n",
            "\n",
            "\n",
            "\n",
            "=============== 52 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -188.36899766899776\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -302.9284382284381\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -198.16596736596745\n",
            "---------- Random -----------\n",
            "total discount reward : \t -216.76759906759904\n",
            "\n",
            "\n",
            "\n",
            "=============== 53 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -222.09090909090915\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -332.4242424242424\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -163.29090909090914\n",
            "---------- Random -----------\n",
            "total discount reward : \t -270.669696969697\n",
            "\n",
            "\n",
            "\n",
            "=============== 54 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -163.06526806526813\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -232.69930069930075\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -127.92424242424237\n",
            "---------- Random -----------\n",
            "total discount reward : \t -235.53846153846146\n",
            "\n",
            "\n",
            "\n",
            "=============== 55 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -167.6456709956709\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -189.44112554112553\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -90.66082251082251\n",
            "---------- Random -----------\n",
            "total discount reward : \t -170.1971861471861\n",
            "\n",
            "\n",
            "\n",
            "=============== 56 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -215.26363636363635\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -285.23333333333335\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -152.41818181818178\n",
            "---------- Random -----------\n",
            "total discount reward : \t -266.7939393939393\n",
            "\n",
            "\n",
            "\n",
            "=============== 57 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -273.02878787878797\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -356.1287878787877\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -280.67878787878794\n",
            "---------- Random -----------\n",
            "total discount reward : \t -334.8454545454544\n",
            "\n",
            "\n",
            "\n",
            "=============== 58 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -189.14652014652012\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -257.2692307692306\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -155.15567765567758\n",
            "---------- Random -----------\n",
            "total discount reward : \t -178.6849816849816\n",
            "\n",
            "\n",
            "\n",
            "=============== 59 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -123.59653679653672\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -128.61774891774888\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -70.79653679653677\n",
            "---------- Random -----------\n",
            "total discount reward : \t -156.3753246753247\n",
            "\n",
            "\n",
            "\n",
            "=============== 60 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -197.72424242424228\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -187.50432900432892\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -177.07575757575748\n",
            "---------- Random -----------\n",
            "total discount reward : \t -216.05497835497832\n",
            "\n",
            "\n",
            "\n",
            "=============== 61 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -144.1301698301698\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -253.63296703296697\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -201.71868131868123\n",
            "---------- Random -----------\n",
            "total discount reward : \t -202.9777222777223\n",
            "\n",
            "\n",
            "\n",
            "=============== 62 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -126.09230769230767\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -141.7275058275058\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -123.7403263403263\n",
            "---------- Random -----------\n",
            "total discount reward : \t -221.39417249417244\n",
            "\n",
            "\n",
            "\n",
            "=============== 63 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -106.81666666666665\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -117.62727272727271\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -119.93333333333334\n",
            "---------- Random -----------\n",
            "total discount reward : \t -145.0060606060606\n",
            "\n",
            "\n",
            "\n",
            "=============== 64 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -188.03008658008653\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -197.37770562770564\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -123.83008658008654\n",
            "---------- Random -----------\n",
            "total discount reward : \t -186.16341991341994\n",
            "\n",
            "\n",
            "\n",
            "=============== 65 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -183.1556443556444\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -208.85564435564433\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -137.58091908091913\n",
            "---------- Random -----------\n",
            "total discount reward : \t -169.48897768897774\n",
            "\n",
            "\n",
            "\n",
            "=============== 66 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -102.50000000000006\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -87.76666666666667\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -66.09999999999998\n",
            "---------- Random -----------\n",
            "total discount reward : \t -144.86666666666667\n",
            "\n",
            "\n",
            "\n",
            "=============== 67 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -236.22445887445886\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -226.89588744588747\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -208.6244588744589\n",
            "---------- Random -----------\n",
            "total discount reward : \t -210.90779220779228\n",
            "\n",
            "\n",
            "\n",
            "=============== 68 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -251.8302863802864\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -296.1062437562437\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -245.3782717282717\n",
            "---------- Random -----------\n",
            "total discount reward : \t -251.80810855810856\n",
            "\n",
            "\n",
            "\n",
            "=============== 69 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -221.07622377622377\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -285.87622377622364\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -168.74289044289034\n",
            "---------- Random -----------\n",
            "total discount reward : \t -240.359557109557\n",
            "\n",
            "\n",
            "\n",
            "=============== 70 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -131.72857142857143\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -200.2761904761904\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -121.27619047619045\n",
            "---------- Random -----------\n",
            "total discount reward : \t -141.19523809523812\n",
            "\n",
            "\n",
            "\n",
            "=============== 71 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -165.81338661338657\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -196.22247752247745\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -95.67096237096236\n",
            "---------- Random -----------\n",
            "total discount reward : \t -191.94671994671998\n",
            "\n",
            "\n",
            "\n",
            "=============== 72 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -226.95151515151505\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -288.0181818181819\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -257.21818181818185\n",
            "---------- Random -----------\n",
            "total discount reward : \t -241.58484848484846\n",
            "\n",
            "\n",
            "\n",
            "=============== 73 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -185.2756243756244\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -226.73731268731274\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -162.9944555444556\n",
            "---------- Random -----------\n",
            "total discount reward : \t -221.79662004662003\n",
            "\n",
            "\n",
            "\n",
            "=============== 74 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -176.45256410256397\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -293.9216117216117\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -157.60970695970693\n",
            "---------- Random -----------\n",
            "total discount reward : \t -196.7882783882783\n",
            "\n",
            "\n",
            "\n",
            "=============== 75 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -68.17619047619043\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -40.03333333333335\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -39.53333333333335\n",
            "---------- Random -----------\n",
            "total discount reward : \t -95.22380952380948\n",
            "\n",
            "\n",
            "\n",
            "=============== 76 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -67.66020646020647\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -114.04995004994998\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -74.59353979353973\n",
            "---------- Random -----------\n",
            "total discount reward : \t -126.2268731268731\n",
            "\n",
            "\n",
            "\n",
            "=============== 77 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -226.74761904761908\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -204.87337662337666\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -140.11168831168837\n",
            "---------- Random -----------\n",
            "total discount reward : \t -159.5385281385282\n",
            "\n",
            "\n",
            "\n",
            "=============== 78 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -185.36428571428576\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -217.25238095238086\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -141.5142857142857\n",
            "---------- Random -----------\n",
            "total discount reward : \t -241.41428571428563\n",
            "\n",
            "\n",
            "\n",
            "=============== 79 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -288.3351648351646\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -303.07176157176133\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -276.0397102897101\n",
            "---------- Random -----------\n",
            "total discount reward : \t -295.8003163503162\n",
            "\n",
            "\n",
            "\n",
            "=============== 80 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -236.90422910422916\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -285.48772893772883\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -214.67654012653998\n",
            "---------- Random -----------\n",
            "total discount reward : \t -234.47624042624045\n",
            "\n",
            "\n",
            "\n",
            "=============== 81 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -227.51515151515147\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -324.6151515151515\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -296.3151515151515\n",
            "---------- Random -----------\n",
            "total discount reward : \t -303.1151515151516\n",
            "\n",
            "\n",
            "\n",
            "=============== 82 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -115.09613719613715\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -97.86691641691635\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -91.18379953379947\n",
            "---------- Random -----------\n",
            "total discount reward : \t -111.31003996003986\n",
            "\n",
            "\n",
            "\n",
            "=============== 83 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -184.77435897435896\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -227.88333333333333\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -225.37692307692302\n",
            "---------- Random -----------\n",
            "total discount reward : \t -218.7026806526806\n",
            "\n",
            "\n",
            "\n",
            "=============== 84 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -186.24309024309025\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -295.64252414252405\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -235.76893106893112\n",
            "---------- Random -----------\n",
            "total discount reward : \t -221.93906093906097\n",
            "\n",
            "\n",
            "\n",
            "=============== 85 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -100.40034965034964\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -106.68030303030302\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -89.84696969696965\n",
            "---------- Random -----------\n",
            "total discount reward : \t -119.63904428904426\n",
            "\n",
            "\n",
            "\n",
            "=============== 86 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -107.51666666666665\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -127.88809523809525\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -135.1619047619048\n",
            "---------- Random -----------\n",
            "total discount reward : \t -165.87380952380957\n",
            "\n",
            "\n",
            "\n",
            "=============== 87 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -178.11666666666667\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -192.34688644688654\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -180.95329670329676\n",
            "---------- Random -----------\n",
            "total discount reward : \t -187.0712454212454\n",
            "\n",
            "\n",
            "\n",
            "=============== 88 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -216.4166666666667\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -319.82575757575745\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -215.5530303030303\n",
            "---------- Random -----------\n",
            "total discount reward : \t -234.0681818181819\n",
            "\n",
            "\n",
            "\n",
            "=============== 89 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -123.38003663003659\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -181.00183150183162\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -110.22362637362633\n",
            "---------- Random -----------\n",
            "total discount reward : \t -204.45695970695974\n",
            "\n",
            "\n",
            "\n",
            "=============== 90 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -229.46693306693308\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -303.9801198801199\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -227.70049950049955\n",
            "---------- Random -----------\n",
            "total discount reward : \t -202.5771894771895\n",
            "\n",
            "\n",
            "\n",
            "=============== 91 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -247.0524475524476\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -247.50349650349656\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -159.65850815850828\n",
            "---------- Random -----------\n",
            "total discount reward : \t -295.4009324009323\n",
            "\n",
            "\n",
            "\n",
            "=============== 92 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -193.79956709956707\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -220.61623376623376\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -170.06623376623375\n",
            "---------- Random -----------\n",
            "total discount reward : \t -182.14956709956704\n",
            "\n",
            "\n",
            "\n",
            "=============== 93 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -206.33589743589738\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -153.03333333333327\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -151.73333333333335\n",
            "---------- Random -----------\n",
            "total discount reward : \t -241.51025641025643\n",
            "\n",
            "\n",
            "\n",
            "=============== 94 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -151.21048951048965\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -206.06503496503495\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -82.98484848484847\n",
            "---------- Random -----------\n",
            "total discount reward : \t -193.27715617715623\n",
            "\n",
            "\n",
            "\n",
            "=============== 95 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -147.55714285714274\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -174.6309523809523\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -131.38809523809525\n",
            "---------- Random -----------\n",
            "total discount reward : \t -141.31190476190474\n",
            "\n",
            "\n",
            "\n",
            "=============== 96 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -116.3823176823176\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -212.2591075591076\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -90.14105894105892\n",
            "---------- Random -----------\n",
            "total discount reward : \t -146.97555777555777\n",
            "\n",
            "\n",
            "\n",
            "=============== 97 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -119.20879120879127\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -135.31135531135524\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -152.34981684981673\n",
            "---------- Random -----------\n",
            "total discount reward : \t -140.86263736263732\n",
            "\n",
            "\n",
            "\n",
            "=============== 98 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -116.9205128205128\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -75.92051282051283\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -62.92051282051283\n",
            "---------- Random -----------\n",
            "total discount reward : \t -126.58717948717947\n",
            "\n",
            "\n",
            "\n",
            "=============== 99 ===============\n",
            "network_input_height= 20\n",
            "network_input_width= 124.0\n",
            "network_output_dim= 6\n",
            " params= [W, b, W, b]  count= 49746\n",
            "lr_rate= 0.001\n",
            "---------- PG -----------\n",
            "total discount reward : \t -197.18181818181824\n",
            "---------- Tetris -----------\n",
            "total discount reward : \t -187.08181818181822\n",
            "---------- SJF -----------\n",
            "total discount reward : \t -137.34848484848493\n",
            "---------- Random -----------\n",
            "total discount reward : \t -238.14848484848486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5mIKoUFdWm_"
      },
      "source": [
        "Results can be seen in outputted file pg_re_learning_curve.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8sJnCdRdqMI"
      },
      "source": [
        "Enjoy!"
      ]
    }
  ]
}